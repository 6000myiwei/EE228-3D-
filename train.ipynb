{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from dataloader import ClfDataset,ClfSegDataset, ClfAttentionDataset, get_balanced_loader, get_loader, get_mixup_gen\n",
    "from mylib.models import densenet, densenetf , resnet,  metrics, losses,densenetf_avr\n",
    "\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau,LearningRateScheduler\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "lines = pd.read_csv('train_10fold.csv')\n",
    "\n",
    "def main(batch_sizes, crop_size, random_move, learning_rate,\n",
    "         model_path, train_subset, val_subset,\n",
    "         segmentation_task_ratio, weight_decay, save_folder, epochs):\n",
    "    '''\n",
    "    :param batch_sizes: the number of examples of each class in a single batch\n",
    "    :param crop_size: the input size\n",
    "    :param random_move: the random move in data augmentation\n",
    "    :param learning_rate: learning rate of the optimizer\n",
    "    :param segmentation_task_ratio: the weight of segmentation loss in total loss\n",
    "    :param weight_decay: l2 weight decay\n",
    "    :param save_folder: where to save the snapshots, tensorflow logs, etc.\n",
    "    :param epochs: how many epochs to run\n",
    "    :return:\n",
    "    '''\n",
    "    batch_size = sum(batch_sizes)\n",
    "\n",
    "    train_dataset = ClfAttentionDataset(crop_size=crop_size, subset=train_subset, move=random_move,lines=lines)\n",
    "\n",
    "    val_dataset = ClfAttentionDataset(crop_size=crop_size, subset=val_subset, move=None,lines=lines)\n",
    "    \n",
    "    g1 = get_balanced_loader(train_dataset, batch_sizes=batch_sizes)\n",
    "    \n",
    "    g2 = get_loader(train_dataset, batch_size=batch_size)\n",
    "    \n",
    "    train_loader = get_mixup_gen(g1,g2,0.3,batch_size)\n",
    "    \n",
    "    val_loader = get_loader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    model = densenetf_avr.get_compiled(output_size=2,\n",
    "                                    optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "                                    loss='categorical_crossentropy',\n",
    "                                    metrics=['accuracy', metrics.precision, metrics.recall, metrics.fmeasure],\n",
    "                                    weights = model_path,\n",
    "                                    weight_decay=weight_decay)\n",
    "    \n",
    "    def lr_sch(epoch):\n",
    "        #120 total\n",
    "        if epoch <10:\n",
    "            return 1e-3\n",
    "        if 10<=epoch<30:\n",
    "            return 3e-4\n",
    "        if 30<=epoch<50:\n",
    "            return 1e-4\n",
    "        if 50<=epoch<70:\n",
    "            return 1e-5\n",
    "        if 70<=epoch<90:\n",
    "            return 1e-6\n",
    "        if 90<=epoch<110:\n",
    "            return 1e-7\n",
    "        if 110<=epoch<120:\n",
    "            return 5e-8\n",
    "    \n",
    "    lr_scheduler = LearningRateScheduler(lr_sch)\n",
    "\n",
    "    # checkpointer = ModelCheckpoint(filepath='tmp/%s/weights.{epoch:02d}.h5' % save_folder, verbose=1,\n",
    "    #                                period=1, save_weights_only=True, monitor='val_accuracy')\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='tmp/%s/weights.{epoch:02d}.h5' % save_folder, verbose=1,\n",
    "                                   period=1, save_weights_only=True, monitor='val_accuracy')\n",
    "    \n",
    "    best_keeper = ModelCheckpoint(filepath='tmp/%s/best.h5' % save_folder, verbose=1, save_weights_only=True,\n",
    "                                  monitor='val_accuracy', save_best_only=True, period=1, mode='auto')\n",
    "    csv_logger = CSVLogger('tmp/%s/training.csv' % save_folder)\n",
    "    \n",
    "    tensorboard = TensorBoard(log_dir='tmp/%s/logs/' % save_folder, profile_batch = 100000000)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, mode='auto',\n",
    "                                   patience=140, verbose=1)\n",
    "    lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.334, patience=10,\n",
    "                                   verbose=1, mode='auto', epsilon=1.e-5, cooldown=2, min_lr=0)\n",
    "\n",
    "    model.fit_generator(generator=train_loader, steps_per_epoch=len(train_dataset) // batch_size, max_queue_size=500,\n",
    "                        validation_data=val_loader, epochs=epochs, validation_steps=len(val_dataset) // batch_size,\n",
    "                        callbacks=[checkpointer, early_stopping, best_keeper, lr_reducer, csv_logger, tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if __name__ == '__main__':\n",
    "    from random import shuffle\n",
    "    best_model = None\n",
    "    for j in range(5):\n",
    "        x = [0,1,2,3,4]       \n",
    "        shuffle(x)\n",
    "        for i in x:\n",
    "            index = list(range(5))\n",
    "            val_subset = [index.pop(i)]\n",
    "            train_subset = index\n",
    "            main(batch_sizes=[2, 2],\n",
    "                 crop_size=[32, 32, 32],\n",
    "                 train_subset = train_subset,\n",
    "                 val_subset = val_subset,\n",
    "                 model_path = best_model,\n",
    "                 random_move=3,\n",
    "                 learning_rate=1.e-4 * (0.333 ** j),\n",
    "                 segmentation_task_ratio=0.2,\n",
    "                 weight_decay=0.,\n",
    "                 save_folder='test',\n",
    "                 epochs=20)\n",
    "            best_model = './tmp/test/weights.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(10):\n",
    "    index = list(range(10))\n",
    "\n",
    "    val_subset = [10]\n",
    "    train_subset = index\n",
    "\n",
    "    main(batch_sizes=[2, 2],\n",
    "          crop_size=[32, 32, 32],\n",
    "          train_subset = train_subset,\n",
    "          val_subset = val_subset,\n",
    "          model_path = None,\n",
    "          random_move=3,\n",
    "          learning_rate=3e-4,\n",
    "          segmentation_task_ratio=0.2,\n",
    "          weight_decay=1e-6,\n",
    "          save_folder='10foldval(124nols)_%d'%i,\n",
    "          epochs=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model hyper-parameters: {'activation': <function <lambda> at 0x000001DE5883BE58>, 'bn_scale': True, 'weight_decay': 1e-06, 'kernel_initializer': 'he_uniform', 'first_scale': <function <lambda> at 0x000001DE58839948>, 'dhw': [32, 32, 32], 'k': 18, 'bottleneck': [2, 2, 4], 'compression': 2, 'first_layer': 32, 'down_structure': [2, 2, 4], 'output_size': 2, 'dropout_rate': None}\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 32,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 32, 32, 32, 1 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 32, 32, 32, 3 896         lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 32, 3 128         conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 32, 3 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 32, 32, 32, 3 1152        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 32, 3 144         conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 32, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 32, 32, 32, 1 17514       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 32, 5 0           conv3d_2[0][0]                   \n",
      "                                                                 conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 32, 5 200         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 32, 5 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 32, 32, 32, 3 1800        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 32, 3 144         conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 32, 3 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 32, 32, 32, 1 17514       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 32, 6 0           conv3d_4[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 32, 6 272         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 32, 6 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 32, 32, 32, 3 2346        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling3d (AveragePooli (None, 16, 16, 16, 3 0           conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 16, 3 136         average_pooling3d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 16, 3 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 16, 16, 16, 3 1224        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 16, 3 144         conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 16, 3 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 16, 16, 16, 1 17514       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 16, 5 0           conv3d_7[0][0]                   \n",
      "                                                                 average_pooling3d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 16, 5 208         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 16, 5 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 16, 16, 16, 3 1872        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 16, 3 144         conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 16, 3 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 16, 16, 16, 1 17514       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 16, 7 0           conv3d_9[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 16, 7 280         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 16, 7 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 16, 16, 16, 3 2485        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling3d_1 (AveragePoo (None, 8, 8, 8, 35)  0           conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 8, 35)  140         average_pooling3d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 8, 35)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 8, 8, 8, 72)  2520        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 8, 72)  288         conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 8, 72)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 8, 8, 8, 18)  35010       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 8, 8, 53)  0           conv3d_12[0][0]                  \n",
      "                                                                 average_pooling3d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 8, 53)  212         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 8, 53)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 8, 8, 8, 72)  3816        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 8, 72)  288         conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 8, 72)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 8, 8, 8, 18)  35010       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8, 8, 8, 71)  0           conv3d_14[0][0]                  \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 8, 71)  284         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 8, 71)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 8, 8, 8, 72)  5112        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 8, 72)  288         conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 8, 72)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 8, 8, 8, 18)  35010       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 8, 8, 8, 89)  0           conv3d_16[0][0]                  \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 8, 89)  356         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 8, 89)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 8, 8, 8, 72)  6408        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 8, 72)  288         conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 8, 72)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 8, 8, 8, 18)  35010       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 8, 8, 8, 107) 0           conv3d_18[0][0]                  \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 8, 107) 428         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 8, 107) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d (Globa (None, 107)          0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            216         global_average_pooling3d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 244,315\n",
      "Trainable params: 242,129\n",
      "Non-trainable params: 2,186\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-c7baafbaee06>:88: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Size 465\n",
      "Size 465\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Size 92\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 116 steps, validate for 23 steps\n",
      "Epoch 1/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.7218 - categorical_crossentropy: 0.7204 - accuracy: 0.5326 - precision: 0.4174 - recall: 0.4174 - fmeasure: 0.4174\n",
      "Epoch 00001: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.01.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.46739, saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/best.h5\n",
      "116/116 [==============================] - 20s 176ms/step - loss: 0.7213 - categorical_crossentropy: 0.7200 - accuracy: 0.5345 - precision: 0.4138 - recall: 0.4138 - fmeasure: 0.4138 - val_loss: 1.0919 - val_categorical_crossentropy: 1.0906 - val_accuracy: 0.4674 - val_precision: 0.4674 - val_recall: 0.4674 - val_fmeasure: 0.4674\n",
      "Epoch 2/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6998 - categorical_crossentropy: 0.6985 - accuracy: 0.5652 - precision: 0.4435 - recall: 0.4435 - fmeasure: 0.4435\n",
      "Epoch 00002: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.02.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.46739\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.7008 - categorical_crossentropy: 0.6995 - accuracy: 0.5647 - precision: 0.4418 - recall: 0.4418 - fmeasure: 0.4418 - val_loss: 0.7319 - val_categorical_crossentropy: 0.7305 - val_accuracy: 0.4457 - val_precision: 0.3913 - val_recall: 0.3913 - val_fmeasure: 0.3913\n",
      "Epoch 3/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6935 - categorical_crossentropy: 0.6921 - accuracy: 0.5522 - precision: 0.4043 - recall: 0.4043 - fmeasure: 0.4043\n",
      "Epoch 00003: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.03.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.46739 to 0.50000, saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/best.h5\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6940 - categorical_crossentropy: 0.6926 - accuracy: 0.5517 - precision: 0.4052 - recall: 0.4052 - fmeasure: 0.4052 - val_loss: 0.7668 - val_categorical_crossentropy: 0.7654 - val_accuracy: 0.5000 - val_precision: 0.4674 - val_recall: 0.4674 - val_fmeasure: 0.4674\n",
      "Epoch 4/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6850 - categorical_crossentropy: 0.6837 - accuracy: 0.5630 - precision: 0.4130 - recall: 0.4130 - fmeasure: 0.4130\n",
      "Epoch 00004: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.04.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.50000 to 0.55435, saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/best.h5\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6840 - categorical_crossentropy: 0.6826 - accuracy: 0.5647 - precision: 0.4159 - recall: 0.4159 - fmeasure: 0.4159 - val_loss: 0.7426 - val_categorical_crossentropy: 0.7413 - val_accuracy: 0.5543 - val_precision: 0.5435 - val_recall: 0.5435 - val_fmeasure: 0.5435\n",
      "Epoch 5/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6849 - categorical_crossentropy: 0.6835 - accuracy: 0.5717 - precision: 0.4522 - recall: 0.4522 - fmeasure: 0.4522\n",
      "Epoch 00005: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.05.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.55435 to 0.58696, saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/best.h5\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6859 - categorical_crossentropy: 0.6846 - accuracy: 0.5711 - precision: 0.4526 - recall: 0.4526 - fmeasure: 0.4526 - val_loss: 0.6797 - val_categorical_crossentropy: 0.6783 - val_accuracy: 0.5870 - val_precision: 0.5435 - val_recall: 0.5435 - val_fmeasure: 0.5435\n",
      "Epoch 6/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6777 - categorical_crossentropy: 0.6764 - accuracy: 0.5957 - precision: 0.4478 - recall: 0.4478 - fmeasure: 0.4478\n",
      "Epoch 00006: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.06.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.58696 to 0.61957, saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/best.h5\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6772 - categorical_crossentropy: 0.6759 - accuracy: 0.5970 - precision: 0.4504 - recall: 0.4504 - fmeasure: 0.4504 - val_loss: 0.6604 - val_categorical_crossentropy: 0.6590 - val_accuracy: 0.6196 - val_precision: 0.5870 - val_recall: 0.5870 - val_fmeasure: 0.5870\n",
      "Epoch 7/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6714 - categorical_crossentropy: 0.6701 - accuracy: 0.6217 - precision: 0.4978 - recall: 0.4978 - fmeasure: 0.4978\n",
      "Epoch 00007: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.07.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.61957\n",
      "116/116 [==============================] - 14s 118ms/step - loss: 0.6706 - categorical_crossentropy: 0.6692 - accuracy: 0.6228 - precision: 0.5000 - recall: 0.5000 - fmeasure: 0.5000 - val_loss: 0.8949 - val_categorical_crossentropy: 0.8936 - val_accuracy: 0.5109 - val_precision: 0.5109 - val_recall: 0.5109 - val_fmeasure: 0.5109\n",
      "Epoch 8/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6839 - categorical_crossentropy: 0.6826 - accuracy: 0.5696 - precision: 0.4435 - recall: 0.4435 - fmeasure: 0.4435\n",
      "Epoch 00008: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.08.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.61957\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6835 - categorical_crossentropy: 0.6821 - accuracy: 0.5711 - precision: 0.4461 - recall: 0.4461 - fmeasure: 0.4461 - val_loss: 0.8777 - val_categorical_crossentropy: 0.8763 - val_accuracy: 0.4130 - val_precision: 0.3152 - val_recall: 0.3152 - val_fmeasure: 0.3152\n",
      "Epoch 9/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6780 - categorical_crossentropy: 0.6766 - accuracy: 0.6174 - precision: 0.4783 - recall: 0.4783 - fmeasure: 0.4783\n",
      "Epoch 00009: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.09.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.61957 to 0.63043, saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/best.h5\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6770 - categorical_crossentropy: 0.6757 - accuracy: 0.6185 - precision: 0.4806 - recall: 0.4806 - fmeasure: 0.4806 - val_loss: 0.6624 - val_categorical_crossentropy: 0.6610 - val_accuracy: 0.6304 - val_precision: 0.5978 - val_recall: 0.5978 - val_fmeasure: 0.5978\n",
      "Epoch 10/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6651 - categorical_crossentropy: 0.6638 - accuracy: 0.6283 - precision: 0.5217 - recall: 0.5217 - fmeasure: 0.5217\n",
      "Epoch 00010: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.10.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.63043\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6644 - categorical_crossentropy: 0.6630 - accuracy: 0.6293 - precision: 0.5216 - recall: 0.5216 - fmeasure: 0.5216 - val_loss: 0.6913 - val_categorical_crossentropy: 0.6900 - val_accuracy: 0.5652 - val_precision: 0.5652 - val_recall: 0.5652 - val_fmeasure: 0.5652\n",
      "Epoch 11/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6755 - categorical_crossentropy: 0.6741 - accuracy: 0.5935 - precision: 0.4370 - recall: 0.4370 - fmeasure: 0.4370\n",
      "Epoch 00011: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.11.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.63043 to 0.67391, saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/best.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 14s 118ms/step - loss: 0.6737 - categorical_crossentropy: 0.6723 - accuracy: 0.5948 - precision: 0.4397 - recall: 0.4397 - fmeasure: 0.4397 - val_loss: 0.6725 - val_categorical_crossentropy: 0.6711 - val_accuracy: 0.6739 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 12/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6819 - categorical_crossentropy: 0.6805 - accuracy: 0.5739 - precision: 0.4522 - recall: 0.4522 - fmeasure: 0.4522\n",
      "Epoch 00012: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.12.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67391\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6829 - categorical_crossentropy: 0.6815 - accuracy: 0.5690 - precision: 0.4483 - recall: 0.4483 - fmeasure: 0.4483 - val_loss: 0.6610 - val_categorical_crossentropy: 0.6597 - val_accuracy: 0.6522 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 13/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6600 - categorical_crossentropy: 0.6587 - accuracy: 0.6283 - precision: 0.5022 - recall: 0.5022 - fmeasure: 0.5022\n",
      "Epoch 00013: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.13.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67391\n",
      "116/116 [==============================] - 13s 114ms/step - loss: 0.6599 - categorical_crossentropy: 0.6585 - accuracy: 0.6272 - precision: 0.5022 - recall: 0.5022 - fmeasure: 0.5022 - val_loss: 0.6816 - val_categorical_crossentropy: 0.6803 - val_accuracy: 0.6739 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 14/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6632 - categorical_crossentropy: 0.6618 - accuracy: 0.6326 - precision: 0.5087 - recall: 0.5087 - fmeasure: 0.5087- ETA: 5s - loss: 0.6586 - categorical_crossentropy: 0.6572 - accuracy\n",
      "Epoch 00014: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.14.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67391\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6638 - categorical_crossentropy: 0.6624 - accuracy: 0.6315 - precision: 0.5043 - recall: 0.5043 - fmeasure: 0.5043 - val_loss: 0.7622 - val_categorical_crossentropy: 0.7609 - val_accuracy: 0.5761 - val_precision: 0.5761 - val_recall: 0.5761 - val_fmeasure: 0.5761\n",
      "Epoch 15/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6772 - categorical_crossentropy: 0.6758 - accuracy: 0.6000 - precision: 0.4870 - recall: 0.4870 - fmeasure: 0.4870\n",
      "Epoch 00015: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.15.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67391\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6769 - categorical_crossentropy: 0.6755 - accuracy: 0.5991 - precision: 0.4871 - recall: 0.4871 - fmeasure: 0.4871 - val_loss: 0.6892 - val_categorical_crossentropy: 0.6879 - val_accuracy: 0.6304 - val_precision: 0.5978 - val_recall: 0.5978 - val_fmeasure: 0.5978\n",
      "Epoch 16/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6539 - categorical_crossentropy: 0.6526 - accuracy: 0.6500 - precision: 0.5109 - recall: 0.5109 - fmeasure: 0.5109\n",
      "Epoch 00016: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.16.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.67391 to 0.69565, saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/best.h5\n",
      "116/116 [==============================] - 14s 120ms/step - loss: 0.6536 - categorical_crossentropy: 0.6522 - accuracy: 0.6509 - precision: 0.5129 - recall: 0.5129 - fmeasure: 0.5129 - val_loss: 0.6970 - val_categorical_crossentropy: 0.6956 - val_accuracy: 0.6957 - val_precision: 0.6739 - val_recall: 0.6739 - val_fmeasure: 0.6739\n",
      "Epoch 17/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6685 - categorical_crossentropy: 0.6671 - accuracy: 0.6326 - precision: 0.5043 - recall: 0.5043 - fmeasure: 0.5043\n",
      "Epoch 00017: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.17.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6679 - categorical_crossentropy: 0.6665 - accuracy: 0.6358 - precision: 0.5043 - recall: 0.5043 - fmeasure: 0.5043 - val_loss: 0.7086 - val_categorical_crossentropy: 0.7072 - val_accuracy: 0.5652 - val_precision: 0.5435 - val_recall: 0.5435 - val_fmeasure: 0.5435\n",
      "Epoch 18/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6500 - categorical_crossentropy: 0.6486 - accuracy: 0.6261 - precision: 0.5152 - recall: 0.5152 - fmeasure: 0.5152\n",
      "Epoch 00018: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.18.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 13s 113ms/step - loss: 0.6489 - categorical_crossentropy: 0.6475 - accuracy: 0.6293 - precision: 0.5194 - recall: 0.5194 - fmeasure: 0.5194 - val_loss: 0.6980 - val_categorical_crossentropy: 0.6966 - val_accuracy: 0.6196 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 19/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6727 - categorical_crossentropy: 0.6713 - accuracy: 0.6022 - precision: 0.4783 - recall: 0.4783 - fmeasure: 0.4783- ETA: 7s - loss: 0.6190 -\n",
      "Epoch 00019: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.19.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 14s 119ms/step - loss: 0.6751 - categorical_crossentropy: 0.6737 - accuracy: 0.5991 - precision: 0.4763 - recall: 0.4763 - fmeasure: 0.4763 - val_loss: 0.7068 - val_categorical_crossentropy: 0.7055 - val_accuracy: 0.6848 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 20/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6815 - categorical_crossentropy: 0.6801 - accuracy: 0.5913 - precision: 0.4565 - recall: 0.4565 - fmeasure: 0.4565- ETA: 8s - loss: 0.6855\n",
      "Epoch 00020: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.20.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6819 - categorical_crossentropy: 0.6805 - accuracy: 0.5905 - precision: 0.4569 - recall: 0.4569 - fmeasure: 0.4569 - val_loss: 0.6804 - val_categorical_crossentropy: 0.6790 - val_accuracy: 0.5326 - val_precision: 0.5000 - val_recall: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 21/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6630 - categorical_crossentropy: 0.6616 - accuracy: 0.6326 - precision: 0.5000 - recall: 0.5000 - fmeasure: 0.5000\n",
      "Epoch 00021: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.21.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 13s 114ms/step - loss: 0.6627 - categorical_crossentropy: 0.6613 - accuracy: 0.6336 - precision: 0.5000 - recall: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6330 - val_categorical_crossentropy: 0.6316 - val_accuracy: 0.6739 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 22/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6461 - categorical_crossentropy: 0.6448 - accuracy: 0.6500 - precision: 0.5478 - recall: 0.5478 - fmeasure: 0.5478\n",
      "Epoch 00022: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.22.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 13s 114ms/step - loss: 0.6462 - categorical_crossentropy: 0.6449 - accuracy: 0.6487 - precision: 0.5474 - recall: 0.5474 - fmeasure: 0.5474 - val_loss: 0.6578 - val_categorical_crossentropy: 0.6565 - val_accuracy: 0.6087 - val_precision: 0.5978 - val_recall: 0.5978 - val_fmeasure: 0.5978\n",
      "Epoch 23/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6611 - categorical_crossentropy: 0.6597 - accuracy: 0.6152 - precision: 0.5065 - recall: 0.5065 - fmeasure: 0.5065\n",
      "Epoch 00023: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.23.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.69565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6610 - categorical_crossentropy: 0.6597 - accuracy: 0.6164 - precision: 0.5086 - recall: 0.5086 - fmeasure: 0.5086 - val_loss: 0.6929 - val_categorical_crossentropy: 0.6915 - val_accuracy: 0.6196 - val_precision: 0.5761 - val_recall: 0.5761 - val_fmeasure: 0.5761\n",
      "Epoch 24/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6792 - categorical_crossentropy: 0.6779 - accuracy: 0.5804 - precision: 0.4304 - recall: 0.4304 - fmeasure: 0.4304\n",
      "Epoch 00024: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.24.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 14s 122ms/step - loss: 0.6795 - categorical_crossentropy: 0.6781 - accuracy: 0.5797 - precision: 0.4310 - recall: 0.4310 - fmeasure: 0.4310 - val_loss: 0.6673 - val_categorical_crossentropy: 0.6659 - val_accuracy: 0.5652 - val_precision: 0.5326 - val_recall: 0.5326 - val_fmeasure: 0.5326\n",
      "Epoch 25/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6789 - categorical_crossentropy: 0.6775 - accuracy: 0.5630 - precision: 0.4435 - recall: 0.4435 - fmeasure: 0.4435\n",
      "Epoch 00025: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.25.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 14s 118ms/step - loss: 0.6778 - categorical_crossentropy: 0.6764 - accuracy: 0.5668 - precision: 0.4440 - recall: 0.4440 - fmeasure: 0.4440 - val_loss: 0.6777 - val_categorical_crossentropy: 0.6763 - val_accuracy: 0.6087 - val_precision: 0.5761 - val_recall: 0.5761 - val_fmeasure: 0.5761\n",
      "Epoch 26/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6674 - categorical_crossentropy: 0.6660 - accuracy: 0.6196 - precision: 0.4674 - recall: 0.4674 - fmeasure: 0.4674\n",
      "Epoch 00026: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.26.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.69565\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00010020000475924463.\n",
      "116/116 [==============================] - 14s 118ms/step - loss: 0.6662 - categorical_crossentropy: 0.6648 - accuracy: 0.6228 - precision: 0.4720 - recall: 0.4720 - fmeasure: 0.4720 - val_loss: 0.6525 - val_categorical_crossentropy: 0.6511 - val_accuracy: 0.6522 - val_precision: 0.5761 - val_recall: 0.5761 - val_fmeasure: 0.5761\n",
      "Epoch 27/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6708 - categorical_crossentropy: 0.6694 - accuracy: 0.6217 - precision: 0.4913 - recall: 0.4913 - fmeasure: 0.4913\n",
      "Epoch 00027: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.27.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 14s 118ms/step - loss: 0.6710 - categorical_crossentropy: 0.6696 - accuracy: 0.6228 - precision: 0.4914 - recall: 0.4914 - fmeasure: 0.4914 - val_loss: 0.6515 - val_categorical_crossentropy: 0.6501 - val_accuracy: 0.6630 - val_precision: 0.5761 - val_recall: 0.5761 - val_fmeasure: 0.5761\n",
      "Epoch 28/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6611 - categorical_crossentropy: 0.6597 - accuracy: 0.6174 - precision: 0.4826 - recall: 0.4826 - fmeasure: 0.4826\n",
      "Epoch 00028: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.28.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6612 - categorical_crossentropy: 0.6598 - accuracy: 0.6185 - precision: 0.4806 - recall: 0.4806 - fmeasure: 0.4806 - val_loss: 0.6268 - val_categorical_crossentropy: 0.6254 - val_accuracy: 0.6957 - val_precision: 0.6630 - val_recall: 0.6630 - val_fmeasure: 0.6630\n",
      "Epoch 29/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6727 - categorical_crossentropy: 0.6714 - accuracy: 0.5978 - precision: 0.4587 - recall: 0.4587 - fmeasure: 0.4587\n",
      "Epoch 00029: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.29.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6739 - categorical_crossentropy: 0.6725 - accuracy: 0.5948 - precision: 0.4569 - recall: 0.4569 - fmeasure: 0.4569 - val_loss: 0.6240 - val_categorical_crossentropy: 0.6226 - val_accuracy: 0.6848 - val_precision: 0.6848 - val_recall: 0.6848 - val_fmeasure: 0.6848\n",
      "Epoch 30/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6472 - categorical_crossentropy: 0.6458 - accuracy: 0.6870 - precision: 0.5391 - recall: 0.5391 - fmeasure: 0.5391\n",
      "Epoch 00030: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.30.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 13s 114ms/step - loss: 0.6475 - categorical_crossentropy: 0.6461 - accuracy: 0.6832 - precision: 0.5366 - recall: 0.5366 - fmeasure: 0.5366 - val_loss: 0.6586 - val_categorical_crossentropy: 0.6572 - val_accuracy: 0.6848 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 31/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6607 - categorical_crossentropy: 0.6593 - accuracy: 0.6217 - precision: 0.4978 - recall: 0.4978 - fmeasure: 0.4978\n",
      "Epoch 00031: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.31.h5\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6609 - categorical_crossentropy: 0.6595 - accuracy: 0.6228 - precision: 0.4978 - recall: 0.4978 - fmeasure: 0.4978 - val_loss: 0.6529 - val_categorical_crossentropy: 0.6515 - val_accuracy: 0.6630 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 32/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6653 - categorical_crossentropy: 0.6639 - accuracy: 0.6391 - precision: 0.4870 - recall: 0.4870 - fmeasure: 0.4870\n",
      "Epoch 00032: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.32.h5\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6672 - categorical_crossentropy: 0.6658 - accuracy: 0.6358 - precision: 0.4849 - recall: 0.4849 - fmeasure: 0.4849 - val_loss: 0.6971 - val_categorical_crossentropy: 0.6957 - val_accuracy: 0.5761 - val_precision: 0.5652 - val_recall: 0.5652 - val_fmeasure: 0.5652\n",
      "Epoch 33/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6531 - categorical_crossentropy: 0.6517 - accuracy: 0.6326 - precision: 0.5174 - recall: 0.5174 - fmeasure: 0.5174\n",
      "Epoch 00033: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.33.h5\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 14s 118ms/step - loss: 0.6528 - categorical_crossentropy: 0.6514 - accuracy: 0.6336 - precision: 0.5194 - recall: 0.5194 - fmeasure: 0.5194 - val_loss: 0.6766 - val_categorical_crossentropy: 0.6752 - val_accuracy: 0.6413 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 34/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6696 - categorical_crossentropy: 0.6682 - accuracy: 0.6022 - precision: 0.4587 - recall: 0.4587 - fmeasure: 0.4587\n",
      "Epoch 00034: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.34.h5\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 14s 119ms/step - loss: 0.6701 - categorical_crossentropy: 0.6687 - accuracy: 0.6013 - precision: 0.4591 - recall: 0.4591 - fmeasure: 0.4591 - val_loss: 0.6658 - val_categorical_crossentropy: 0.6644 - val_accuracy: 0.6739 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 35/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6676 - categorical_crossentropy: 0.6662 - accuracy: 0.6130 - precision: 0.4891 - recall: 0.4891 - fmeasure: 0.4891\n",
      "Epoch 00035: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.35.h5\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.69565\n",
      "116/116 [==============================] - 14s 122ms/step - loss: 0.6681 - categorical_crossentropy: 0.6667 - accuracy: 0.6121 - precision: 0.4892 - recall: 0.4892 - fmeasure: 0.4892 - val_loss: 0.6574 - val_categorical_crossentropy: 0.6560 - val_accuracy: 0.6522 - val_precision: 0.6304 - val_recall: 0.6304 - val_fmeasure: 0.6304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6551 - categorical_crossentropy: 0.6537 - accuracy: 0.6391 - precision: 0.4957 - recall: 0.4957 - fmeasure: 0.4957\n",
      "Epoch 00036: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.36.h5\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.69565 to 0.72826, saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/best.h5\n",
      "116/116 [==============================] - 14s 121ms/step - loss: 0.6561 - categorical_crossentropy: 0.6547 - accuracy: 0.6358 - precision: 0.4935 - recall: 0.4935 - fmeasure: 0.4935 - val_loss: 0.6209 - val_categorical_crossentropy: 0.6195 - val_accuracy: 0.7283 - val_precision: 0.7174 - val_recall: 0.7174 - val_fmeasure: 0.7174\n",
      "Epoch 37/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6621 - categorical_crossentropy: 0.6607 - accuracy: 0.6217 - precision: 0.4826 - recall: 0.4826 - fmeasure: 0.4826\n",
      "Epoch 00037: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.37.h5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.72826\n",
      "116/116 [==============================] - 14s 120ms/step - loss: 0.6623 - categorical_crossentropy: 0.6609 - accuracy: 0.6185 - precision: 0.4806 - recall: 0.4806 - fmeasure: 0.4806 - val_loss: 0.6462 - val_categorical_crossentropy: 0.6449 - val_accuracy: 0.6848 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 38/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6572 - categorical_crossentropy: 0.6558 - accuracy: 0.6239 - precision: 0.4935 - recall: 0.4935 - fmeasure: 0.4935\n",
      "Epoch 00038: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.38.h5\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.72826\n",
      "116/116 [==============================] - 14s 122ms/step - loss: 0.6564 - categorical_crossentropy: 0.6550 - accuracy: 0.6250 - precision: 0.4957 - recall: 0.4957 - fmeasure: 0.4957 - val_loss: 0.6690 - val_categorical_crossentropy: 0.6676 - val_accuracy: 0.6196 - val_precision: 0.6087 - val_recall: 0.6087 - val_fmeasure: 0.6087\n",
      "Epoch 39/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6706 - categorical_crossentropy: 0.6692 - accuracy: 0.6152 - precision: 0.4870 - recall: 0.4870 - fmeasure: 0.4870\n",
      "Epoch 00039: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.39.h5\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.72826\n",
      "116/116 [==============================] - 14s 122ms/step - loss: 0.6710 - categorical_crossentropy: 0.6696 - accuracy: 0.6142 - precision: 0.4871 - recall: 0.4871 - fmeasure: 0.4871 - val_loss: 0.6263 - val_categorical_crossentropy: 0.6249 - val_accuracy: 0.7065 - val_precision: 0.6739 - val_recall: 0.6739 - val_fmeasure: 0.6739\n",
      "Epoch 40/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6456 - categorical_crossentropy: 0.6442 - accuracy: 0.6739 - precision: 0.5217 - recall: 0.5217 - fmeasure: 0.5217\n",
      "Epoch 00040: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.40.h5\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.72826\n",
      "116/116 [==============================] - 14s 121ms/step - loss: 0.6481 - categorical_crossentropy: 0.6467 - accuracy: 0.6703 - precision: 0.5172 - recall: 0.5172 - fmeasure: 0.5172 - val_loss: 0.6470 - val_categorical_crossentropy: 0.6456 - val_accuracy: 0.6413 - val_precision: 0.6304 - val_recall: 0.6304 - val_fmeasure: 0.6304\n",
      "Epoch 41/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6701 - categorical_crossentropy: 0.6687 - accuracy: 0.6348 - precision: 0.4652 - recall: 0.4652 - fmeasure: 0.4652\n",
      "Epoch 00041: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.41.h5\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.72826\n",
      "116/116 [==============================] - 14s 121ms/step - loss: 0.6705 - categorical_crossentropy: 0.6691 - accuracy: 0.6336 - precision: 0.4634 - recall: 0.4634 - fmeasure: 0.4634 - val_loss: 0.6176 - val_categorical_crossentropy: 0.6162 - val_accuracy: 0.6957 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 42/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6372 - categorical_crossentropy: 0.6358 - accuracy: 0.6630 - precision: 0.5587 - recall: 0.5587 - fmeasure: 0.5587\n",
      "Epoch 00042: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.42.h5\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.72826 to 0.77174, saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/best.h5\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6368 - categorical_crossentropy: 0.6354 - accuracy: 0.6638 - precision: 0.5582 - recall: 0.5582 - fmeasure: 0.5582 - val_loss: 0.5905 - val_categorical_crossentropy: 0.5891 - val_accuracy: 0.7717 - val_precision: 0.7391 - val_recall: 0.7391 - val_fmeasure: 0.7391\n",
      "Epoch 43/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6677 - categorical_crossentropy: 0.6663 - accuracy: 0.6217 - precision: 0.4783 - recall: 0.4783 - fmeasure: 0.4783\n",
      "Epoch 00043: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.43.h5\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 119ms/step - loss: 0.6679 - categorical_crossentropy: 0.6665 - accuracy: 0.6207 - precision: 0.4763 - recall: 0.4763 - fmeasure: 0.4763 - val_loss: 0.6420 - val_categorical_crossentropy: 0.6406 - val_accuracy: 0.6739 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 44/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6678 - categorical_crossentropy: 0.6664 - accuracy: 0.6261 - precision: 0.4957 - recall: 0.4957 - fmeasure: 0.4957\n",
      "Epoch 00044: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.44.h5\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6673 - categorical_crossentropy: 0.6659 - accuracy: 0.6272 - precision: 0.4978 - recall: 0.4978 - fmeasure: 0.4978 - val_loss: 0.6595 - val_categorical_crossentropy: 0.6581 - val_accuracy: 0.6522 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 45/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6350 - categorical_crossentropy: 0.6336 - accuracy: 0.6739 - precision: 0.5630 - recall: 0.5630 - fmeasure: 0.5630\n",
      "Epoch 00045: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.45.h5\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6362 - categorical_crossentropy: 0.6348 - accuracy: 0.6703 - precision: 0.5603 - recall: 0.5603 - fmeasure: 0.5603 - val_loss: 0.6634 - val_categorical_crossentropy: 0.6620 - val_accuracy: 0.6957 - val_precision: 0.6957 - val_recall: 0.6957 - val_fmeasure: 0.6957\n",
      "Epoch 46/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6556 - categorical_crossentropy: 0.6542 - accuracy: 0.6261 - precision: 0.5174 - recall: 0.5174 - fmeasure: 0.5174\n",
      "Epoch 00046: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.46.h5\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6568 - categorical_crossentropy: 0.6554 - accuracy: 0.6228 - precision: 0.5151 - recall: 0.5151 - fmeasure: 0.5151 - val_loss: 0.6965 - val_categorical_crossentropy: 0.6951 - val_accuracy: 0.6739 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 47/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6564 - categorical_crossentropy: 0.6550 - accuracy: 0.6217 - precision: 0.5261 - recall: 0.5261 - fmeasure: 0.5261\n",
      "Epoch 00047: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.47.h5\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 113ms/step - loss: 0.6555 - categorical_crossentropy: 0.6541 - accuracy: 0.6250 - precision: 0.5280 - recall: 0.5280 - fmeasure: 0.5280 - val_loss: 0.6443 - val_categorical_crossentropy: 0.6429 - val_accuracy: 0.6196 - val_precision: 0.6087 - val_recall: 0.6087 - val_fmeasure: 0.6087\n",
      "Epoch 48/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/116 [============================>.] - ETA: 0s - loss: 0.6555 - categorical_crossentropy: 0.6541 - accuracy: 0.6261 - precision: 0.5065 - recall: 0.5065 - fmeasure: 0.5065\n",
      "Epoch 00048: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.48.h5\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 125ms/step - loss: 0.6553 - categorical_crossentropy: 0.6539 - accuracy: 0.6272 - precision: 0.5086 - recall: 0.5086 - fmeasure: 0.5086 - val_loss: 0.6471 - val_categorical_crossentropy: 0.6457 - val_accuracy: 0.6522 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 49/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6662 - categorical_crossentropy: 0.6648 - accuracy: 0.6239 - precision: 0.4783 - recall: 0.4783 - fmeasure: 0.4783- ETA: 6s - loss: 0.6963 - categorical_\n",
      "Epoch 00049: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.49.h5\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 119ms/step - loss: 0.6657 - categorical_crossentropy: 0.6643 - accuracy: 0.6250 - precision: 0.4784 - recall: 0.4784 - fmeasure: 0.4784 - val_loss: 0.6379 - val_categorical_crossentropy: 0.6365 - val_accuracy: 0.6630 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 50/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6615 - categorical_crossentropy: 0.6601 - accuracy: 0.6348 - precision: 0.4717 - recall: 0.4717 - fmeasure: 0.4717\n",
      "Epoch 00050: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.50.h5\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6615 - categorical_crossentropy: 0.6602 - accuracy: 0.6358 - precision: 0.4741 - recall: 0.4741 - fmeasure: 0.4741 - val_loss: 0.6257 - val_categorical_crossentropy: 0.6243 - val_accuracy: 0.6848 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 51/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6591 - categorical_crossentropy: 0.6577 - accuracy: 0.6196 - precision: 0.4957 - recall: 0.4957 - fmeasure: 0.4957\n",
      "Epoch 00051: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.51.h5\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6593 - categorical_crossentropy: 0.6579 - accuracy: 0.6207 - precision: 0.4957 - recall: 0.4957 - fmeasure: 0.4957 - val_loss: 0.6315 - val_categorical_crossentropy: 0.6301 - val_accuracy: 0.6848 - val_precision: 0.6630 - val_recall: 0.6630 - val_fmeasure: 0.6630\n",
      "Epoch 52/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6543 - categorical_crossentropy: 0.6529 - accuracy: 0.6413 - precision: 0.5196 - recall: 0.5196 - fmeasure: 0.5196\n",
      "Epoch 00052: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.52.h5\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.77174\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 3.346680209506303e-05.\n",
      "116/116 [==============================] - 14s 121ms/step - loss: 0.6542 - categorical_crossentropy: 0.6528 - accuracy: 0.6422 - precision: 0.5216 - recall: 0.5216 - fmeasure: 0.5216 - val_loss: 0.6546 - val_categorical_crossentropy: 0.6532 - val_accuracy: 0.6413 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 53/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6590 - categorical_crossentropy: 0.6576 - accuracy: 0.6717 - precision: 0.5283 - recall: 0.5283 - fmeasure: 0.5283\n",
      "Epoch 00053: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.53.h5\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 118ms/step - loss: 0.6587 - categorical_crossentropy: 0.6573 - accuracy: 0.6703 - precision: 0.5280 - recall: 0.5280 - fmeasure: 0.5280 - val_loss: 0.6143 - val_categorical_crossentropy: 0.6129 - val_accuracy: 0.7065 - val_precision: 0.6848 - val_recall: 0.6848 - val_fmeasure: 0.6848\n",
      "Epoch 54/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6503 - categorical_crossentropy: 0.6489 - accuracy: 0.6543 - precision: 0.5348 - recall: 0.5348 - fmeasure: 0.5348\n",
      "Epoch 00054: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.54.h5\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 124ms/step - loss: 0.6504 - categorical_crossentropy: 0.6490 - accuracy: 0.6530 - precision: 0.5345 - recall: 0.5345 - fmeasure: 0.5345 - val_loss: 0.6163 - val_categorical_crossentropy: 0.6149 - val_accuracy: 0.7065 - val_precision: 0.6848 - val_recall: 0.6848 - val_fmeasure: 0.6848\n",
      "Epoch 55/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6511 - categorical_crossentropy: 0.6497 - accuracy: 0.6522 - precision: 0.5304 - recall: 0.5304 - fmeasure: 0.5304\n",
      "Epoch 00055: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.55.h5\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 123ms/step - loss: 0.6511 - categorical_crossentropy: 0.6497 - accuracy: 0.6509 - precision: 0.5302 - recall: 0.5302 - fmeasure: 0.5302 - val_loss: 0.6217 - val_categorical_crossentropy: 0.6203 - val_accuracy: 0.6957 - val_precision: 0.6957 - val_recall: 0.6957 - val_fmeasure: 0.6957\n",
      "Epoch 56/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6300 - categorical_crossentropy: 0.6286 - accuracy: 0.6978 - precision: 0.5674 - recall: 0.5674 - fmeasure: 0.5674\n",
      "Epoch 00056: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.56.h5\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 118ms/step - loss: 0.6291 - categorical_crossentropy: 0.6277 - accuracy: 0.7004 - precision: 0.5711 - recall: 0.5711 - fmeasure: 0.5711 - val_loss: 0.6278 - val_categorical_crossentropy: 0.6265 - val_accuracy: 0.6848 - val_precision: 0.6630 - val_recall: 0.6630 - val_fmeasure: 0.6630\n",
      "Epoch 57/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6649 - categorical_crossentropy: 0.6635 - accuracy: 0.6174 - precision: 0.4913 - recall: 0.4913 - fmeasure: 0.4913\n",
      "Epoch 00057: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.57.h5\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6634 - categorical_crossentropy: 0.6620 - accuracy: 0.6207 - precision: 0.4957 - recall: 0.4957 - fmeasure: 0.4957 - val_loss: 0.6183 - val_categorical_crossentropy: 0.6169 - val_accuracy: 0.7174 - val_precision: 0.6848 - val_recall: 0.6848 - val_fmeasure: 0.6848\n",
      "Epoch 58/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6410 - categorical_crossentropy: 0.6396 - accuracy: 0.6500 - precision: 0.5435 - recall: 0.5435 - fmeasure: 0.5435\n",
      "Epoch 00058: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.58.h5\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6422 - categorical_crossentropy: 0.6408 - accuracy: 0.6444 - precision: 0.5388 - recall: 0.5388 - fmeasure: 0.5388 - val_loss: 0.6203 - val_categorical_crossentropy: 0.6189 - val_accuracy: 0.7065 - val_precision: 0.6739 - val_recall: 0.6739 - val_fmeasure: 0.6739\n",
      "Epoch 59/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6512 - categorical_crossentropy: 0.6498 - accuracy: 0.6326 - precision: 0.4913 - recall: 0.4913 - fmeasure: 0.4913\n",
      "Epoch 00059: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.59.h5\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 113ms/step - loss: 0.6509 - categorical_crossentropy: 0.6495 - accuracy: 0.6336 - precision: 0.4914 - recall: 0.4914 - fmeasure: 0.4914 - val_loss: 0.6331 - val_categorical_crossentropy: 0.6317 - val_accuracy: 0.6522 - val_precision: 0.6304 - val_recall: 0.6304 - val_fmeasure: 0.6304\n",
      "Epoch 60/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/116 [============================>.] - ETA: 0s - loss: 0.6501 - categorical_crossentropy: 0.6487 - accuracy: 0.6587 - precision: 0.5304 - recall: 0.5304 - fmeasure: 0.5304\n",
      "Epoch 00060: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.60.h5\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 113ms/step - loss: 0.6509 - categorical_crossentropy: 0.6495 - accuracy: 0.6573 - precision: 0.5280 - recall: 0.5280 - fmeasure: 0.5280 - val_loss: 0.6366 - val_categorical_crossentropy: 0.6353 - val_accuracy: 0.6739 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 61/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6580 - categorical_crossentropy: 0.6566 - accuracy: 0.6391 - precision: 0.5304 - recall: 0.5304 - fmeasure: 0.5304\n",
      "Epoch 00061: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.61.h5\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 112ms/step - loss: 0.6572 - categorical_crossentropy: 0.6558 - accuracy: 0.6422 - precision: 0.5323 - recall: 0.5323 - fmeasure: 0.5323 - val_loss: 0.6391 - val_categorical_crossentropy: 0.6377 - val_accuracy: 0.6739 - val_precision: 0.6630 - val_recall: 0.6630 - val_fmeasure: 0.6630\n",
      "Epoch 62/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6424 - categorical_crossentropy: 0.6410 - accuracy: 0.6500 - precision: 0.5413 - recall: 0.5413 - fmeasure: 0.5413- ETA: 6s - loss: 0.6301 - categ\n",
      "Epoch 00062: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.62.h5\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 111ms/step - loss: 0.6436 - categorical_crossentropy: 0.6422 - accuracy: 0.6487 - precision: 0.5388 - recall: 0.5388 - fmeasure: 0.5388 - val_loss: 0.6122 - val_categorical_crossentropy: 0.6108 - val_accuracy: 0.6957 - val_precision: 0.6848 - val_recall: 0.6848 - val_fmeasure: 0.6848\n",
      "Epoch 63/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6682 - categorical_crossentropy: 0.6668 - accuracy: 0.6109 - precision: 0.4761 - recall: 0.4761 - fmeasure: 0.4761\n",
      "Epoch 00063: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.63.h5\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.77174\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.1177912492712494e-05.\n",
      "116/116 [==============================] - 13s 113ms/step - loss: 0.6691 - categorical_crossentropy: 0.6677 - accuracy: 0.6099 - precision: 0.4741 - recall: 0.4741 - fmeasure: 0.4741 - val_loss: 0.6212 - val_categorical_crossentropy: 0.6198 - val_accuracy: 0.6848 - val_precision: 0.6630 - val_recall: 0.6630 - val_fmeasure: 0.6630\n",
      "Epoch 64/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6643 - categorical_crossentropy: 0.6629 - accuracy: 0.6283 - precision: 0.5000 - recall: 0.5000 - fmeasure: 0.5000\n",
      "Epoch 00064: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.64.h5\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6638 - categorical_crossentropy: 0.6624 - accuracy: 0.6293 - precision: 0.5022 - recall: 0.5022 - fmeasure: 0.5022 - val_loss: 0.6235 - val_categorical_crossentropy: 0.6221 - val_accuracy: 0.6957 - val_precision: 0.6087 - val_recall: 0.6087 - val_fmeasure: 0.6087\n",
      "Epoch 65/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6439 - categorical_crossentropy: 0.6425 - accuracy: 0.6587 - precision: 0.5261 - recall: 0.5261 - fmeasure: 0.5261\n",
      "Epoch 00065: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.65.h5\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6438 - categorical_crossentropy: 0.6424 - accuracy: 0.6573 - precision: 0.5259 - recall: 0.5259 - fmeasure: 0.5259 - val_loss: 0.6106 - val_categorical_crossentropy: 0.6092 - val_accuracy: 0.7065 - val_precision: 0.6848 - val_recall: 0.6848 - val_fmeasure: 0.6848\n",
      "Epoch 66/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6639 - categorical_crossentropy: 0.6625 - accuracy: 0.6196 - precision: 0.4891 - recall: 0.4891 - fmeasure: 0.4891\n",
      "Epoch 00066: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.66.h5\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 112ms/step - loss: 0.6628 - categorical_crossentropy: 0.6614 - accuracy: 0.6228 - precision: 0.4892 - recall: 0.4892 - fmeasure: 0.4892 - val_loss: 0.6270 - val_categorical_crossentropy: 0.6256 - val_accuracy: 0.7065 - val_precision: 0.6630 - val_recall: 0.6630 - val_fmeasure: 0.6630\n",
      "Epoch 67/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6603 - categorical_crossentropy: 0.6589 - accuracy: 0.6261 - precision: 0.5109 - recall: 0.5109 - fmeasure: 0.5109\n",
      "Epoch 00067: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.67.h5\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6608 - categorical_crossentropy: 0.6594 - accuracy: 0.6250 - precision: 0.5086 - recall: 0.5086 - fmeasure: 0.5086 - val_loss: 0.5873 - val_categorical_crossentropy: 0.5859 - val_accuracy: 0.7283 - val_precision: 0.6739 - val_recall: 0.6739 - val_fmeasure: 0.6739\n",
      "Epoch 68/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6467 - categorical_crossentropy: 0.6453 - accuracy: 0.6630 - precision: 0.5217 - recall: 0.5217 - fmeasure: 0.5217\n",
      "Epoch 00068: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.68.h5\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 118ms/step - loss: 0.6482 - categorical_crossentropy: 0.6468 - accuracy: 0.6595 - precision: 0.5194 - recall: 0.5194 - fmeasure: 0.5194 - val_loss: 0.6363 - val_categorical_crossentropy: 0.6349 - val_accuracy: 0.6739 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 69/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6622 - categorical_crossentropy: 0.6608 - accuracy: 0.6370 - precision: 0.4978 - recall: 0.4978 - fmeasure: 0.4978\n",
      "Epoch 00069: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.69.h5\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6623 - categorical_crossentropy: 0.6609 - accuracy: 0.6358 - precision: 0.4978 - recall: 0.4978 - fmeasure: 0.4978 - val_loss: 0.6359 - val_categorical_crossentropy: 0.6345 - val_accuracy: 0.6848 - val_precision: 0.6848 - val_recall: 0.6848 - val_fmeasure: 0.6848\n",
      "Epoch 70/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6423 - categorical_crossentropy: 0.6409 - accuracy: 0.6391 - precision: 0.5326 - recall: 0.5326 - fmeasure: 0.5326  ETA: 10s - loss: 0.\n",
      "Epoch 00070: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.70.h5\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6433 - categorical_crossentropy: 0.6419 - accuracy: 0.6358 - precision: 0.5302 - recall: 0.5302 - fmeasure: 0.5302 - val_loss: 0.6306 - val_categorical_crossentropy: 0.6292 - val_accuracy: 0.6848 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 71/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6473 - categorical_crossentropy: 0.6459 - accuracy: 0.6674 - precision: 0.5630 - recall: 0.5630 - fmeasure: 0.5630\n",
      "Epoch 00071: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.71.h5\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6475 - categorical_crossentropy: 0.6461 - accuracy: 0.6659 - precision: 0.5603 - recall: 0.5603 - fmeasure: 0.5603 - val_loss: 0.6847 - val_categorical_crossentropy: 0.6833 - val_accuracy: 0.5870 - val_precision: 0.5543 - val_recall: 0.5543 - val_fmeasure: 0.5543\n",
      "Epoch 72/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/116 [============================>.] - ETA: 0s - loss: 0.6431 - categorical_crossentropy: 0.6417 - accuracy: 0.6565 - precision: 0.5478 - recall: 0.5478 - fmeasure: 0.5478\n",
      "Epoch 00072: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.72.h5\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 118ms/step - loss: 0.6424 - categorical_crossentropy: 0.6410 - accuracy: 0.6595 - precision: 0.5496 - recall: 0.5496 - fmeasure: 0.5496 - val_loss: 0.6193 - val_categorical_crossentropy: 0.6179 - val_accuracy: 0.6848 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 73/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6588 - categorical_crossentropy: 0.6574 - accuracy: 0.6239 - precision: 0.4913 - recall: 0.4913 - fmeasure: 0.4913\n",
      "Epoch 00073: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.73.h5\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6590 - categorical_crossentropy: 0.6576 - accuracy: 0.6250 - precision: 0.4935 - recall: 0.4935 - fmeasure: 0.4935 - val_loss: 0.6049 - val_categorical_crossentropy: 0.6035 - val_accuracy: 0.7391 - val_precision: 0.6957 - val_recall: 0.6957 - val_fmeasure: 0.6957\n",
      "Epoch 74/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6614 - categorical_crossentropy: 0.6600 - accuracy: 0.6348 - precision: 0.5000 - recall: 0.5000 - fmeasure: 0.5000\n",
      "Epoch 00074: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.74.h5\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.77174\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 3.7334228454710684e-06.\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6621 - categorical_crossentropy: 0.6607 - accuracy: 0.6358 - precision: 0.5022 - recall: 0.5022 - fmeasure: 0.5022 - val_loss: 0.6287 - val_categorical_crossentropy: 0.6273 - val_accuracy: 0.6522 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 75/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6494 - categorical_crossentropy: 0.6480 - accuracy: 0.6348 - precision: 0.5261 - recall: 0.5261 - fmeasure: 0.5261\n",
      "Epoch 00075: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.75.h5\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 124ms/step - loss: 0.6495 - categorical_crossentropy: 0.6481 - accuracy: 0.6358 - precision: 0.5237 - recall: 0.5237 - fmeasure: 0.5237 - val_loss: 0.6309 - val_categorical_crossentropy: 0.6295 - val_accuracy: 0.6630 - val_precision: 0.6304 - val_recall: 0.6304 - val_fmeasure: 0.6304\n",
      "Epoch 76/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6656 - categorical_crossentropy: 0.6642 - accuracy: 0.6283 - precision: 0.4935 - recall: 0.4935 - fmeasure: 0.4935\n",
      "Epoch 00076: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.76.h5\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6660 - categorical_crossentropy: 0.6646 - accuracy: 0.6272 - precision: 0.4914 - recall: 0.4914 - fmeasure: 0.4914 - val_loss: 0.6137 - val_categorical_crossentropy: 0.6123 - val_accuracy: 0.6957 - val_precision: 0.6739 - val_recall: 0.6739 - val_fmeasure: 0.6739\n",
      "Epoch 77/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6372 - categorical_crossentropy: 0.6358 - accuracy: 0.6609 - precision: 0.5413 - recall: 0.5413 - fmeasure: 0.5413\n",
      "Epoch 00077: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.77.h5\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6360 - categorical_crossentropy: 0.6346 - accuracy: 0.6616 - precision: 0.5431 - recall: 0.5431 - fmeasure: 0.5431 - val_loss: 0.6448 - val_categorical_crossentropy: 0.6434 - val_accuracy: 0.6522 - val_precision: 0.6304 - val_recall: 0.6304 - val_fmeasure: 0.6304\n",
      "Epoch 78/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6454 - categorical_crossentropy: 0.6440 - accuracy: 0.6696 - precision: 0.5239 - recall: 0.5239 - fmeasure: 0.5239\n",
      "Epoch 00078: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.78.h5\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 121ms/step - loss: 0.6440 - categorical_crossentropy: 0.6426 - accuracy: 0.6724 - precision: 0.5259 - recall: 0.5259 - fmeasure: 0.5259 - val_loss: 0.6494 - val_categorical_crossentropy: 0.6480 - val_accuracy: 0.6304 - val_precision: 0.5870 - val_recall: 0.5870 - val_fmeasure: 0.5870\n",
      "Epoch 79/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6526 - categorical_crossentropy: 0.6512 - accuracy: 0.6196 - precision: 0.4957 - recall: 0.4957 - fmeasure: 0.4957\n",
      "Epoch 00079: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.79.h5\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 112ms/step - loss: 0.6528 - categorical_crossentropy: 0.6514 - accuracy: 0.6164 - precision: 0.4935 - recall: 0.4935 - fmeasure: 0.4935 - val_loss: 0.6471 - val_categorical_crossentropy: 0.6457 - val_accuracy: 0.6413 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 80/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6513 - categorical_crossentropy: 0.6499 - accuracy: 0.6391 - precision: 0.5065 - recall: 0.5065 - fmeasure: 0.5065\n",
      "Epoch 00080: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.80.h5\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 112ms/step - loss: 0.6517 - categorical_crossentropy: 0.6503 - accuracy: 0.6401 - precision: 0.5086 - recall: 0.5086 - fmeasure: 0.5086 - val_loss: 0.6038 - val_categorical_crossentropy: 0.6024 - val_accuracy: 0.7174 - val_precision: 0.6957 - val_recall: 0.6957 - val_fmeasure: 0.6957\n",
      "Epoch 81/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6676 - categorical_crossentropy: 0.6663 - accuracy: 0.6239 - precision: 0.5022 - recall: 0.5022 - fmeasure: 0.5022\n",
      "Epoch 00081: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.81.h5\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 111ms/step - loss: 0.6676 - categorical_crossentropy: 0.6662 - accuracy: 0.6250 - precision: 0.5022 - recall: 0.5022 - fmeasure: 0.5022 - val_loss: 0.6375 - val_categorical_crossentropy: 0.6361 - val_accuracy: 0.6630 - val_precision: 0.5870 - val_recall: 0.5870 - val_fmeasure: 0.5870\n",
      "Epoch 82/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6337 - categorical_crossentropy: 0.6323 - accuracy: 0.6565 - precision: 0.5304 - recall: 0.5304 - fmeasure: 0.5304\n",
      "Epoch 00082: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.82.h5\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 112ms/step - loss: 0.6337 - categorical_crossentropy: 0.6323 - accuracy: 0.6573 - precision: 0.5323 - recall: 0.5323 - fmeasure: 0.5323 - val_loss: 0.6627 - val_categorical_crossentropy: 0.6613 - val_accuracy: 0.6413 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 83/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6519 - categorical_crossentropy: 0.6505 - accuracy: 0.6391 - precision: 0.5283 - recall: 0.5283 - fmeasure: 0.5283\n",
      "Epoch 00083: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.83.h5\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 111ms/step - loss: 0.6501 - categorical_crossentropy: 0.6487 - accuracy: 0.6422 - precision: 0.5323 - recall: 0.5323 - fmeasure: 0.5323 - val_loss: 0.5977 - val_categorical_crossentropy: 0.5963 - val_accuracy: 0.7065 - val_precision: 0.6957 - val_recall: 0.6957 - val_fmeasure: 0.6957\n",
      "Epoch 84/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/116 [============================>.] - ETA: 0s - loss: 0.6460 - categorical_crossentropy: 0.6446 - accuracy: 0.6370 - precision: 0.5283 - recall: 0.5283 - fmeasure: 0.5283\n",
      "Epoch 00084: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.84.h5\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 113ms/step - loss: 0.6467 - categorical_crossentropy: 0.6453 - accuracy: 0.6336 - precision: 0.5259 - recall: 0.5259 - fmeasure: 0.5259 - val_loss: 0.6451 - val_categorical_crossentropy: 0.6437 - val_accuracy: 0.6630 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 85/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6679 - categorical_crossentropy: 0.6665 - accuracy: 0.6130 - precision: 0.4652 - recall: 0.4652 - fmeasure: 0.4652\n",
      "Epoch 00085: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.85.h5\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.77174\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.2469632060856384e-06.\n",
      "116/116 [==============================] - 13s 112ms/step - loss: 0.6679 - categorical_crossentropy: 0.6665 - accuracy: 0.6142 - precision: 0.4655 - recall: 0.4655 - fmeasure: 0.4655 - val_loss: 0.5795 - val_categorical_crossentropy: 0.5781 - val_accuracy: 0.7283 - val_precision: 0.7065 - val_recall: 0.7065 - val_fmeasure: 0.7065\n",
      "Epoch 86/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6361 - categorical_crossentropy: 0.6347 - accuracy: 0.6717 - precision: 0.5500 - recall: 0.5500 - fmeasure: 0.5500\n",
      "Epoch 00086: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.86.h5\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 121ms/step - loss: 0.6346 - categorical_crossentropy: 0.6332 - accuracy: 0.6746 - precision: 0.5539 - recall: 0.5539 - fmeasure: 0.5539 - val_loss: 0.6253 - val_categorical_crossentropy: 0.6239 - val_accuracy: 0.6739 - val_precision: 0.6739 - val_recall: 0.6739 - val_fmeasure: 0.6739\n",
      "Epoch 87/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6627 - categorical_crossentropy: 0.6613 - accuracy: 0.6283 - precision: 0.5000 - recall: 0.5000 - fmeasure: 0.5000\n",
      "Epoch 00087: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.87.h5\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6640 - categorical_crossentropy: 0.6626 - accuracy: 0.6250 - precision: 0.4978 - recall: 0.4978 - fmeasure: 0.4978 - val_loss: 0.6251 - val_categorical_crossentropy: 0.6237 - val_accuracy: 0.6304 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 88/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6399 - categorical_crossentropy: 0.6385 - accuracy: 0.6826 - precision: 0.5630 - recall: 0.5630 - fmeasure: 0.5630\n",
      "Epoch 00088: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.88.h5\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 114ms/step - loss: 0.6401 - categorical_crossentropy: 0.6387 - accuracy: 0.6832 - precision: 0.5647 - recall: 0.5647 - fmeasure: 0.5647 - val_loss: 0.6819 - val_categorical_crossentropy: 0.6805 - val_accuracy: 0.5978 - val_precision: 0.5870 - val_recall: 0.5870 - val_fmeasure: 0.5870\n",
      "Epoch 89/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6426 - categorical_crossentropy: 0.6412 - accuracy: 0.6587 - precision: 0.5239 - recall: 0.5239 - fmeasure: 0.5239\n",
      "Epoch 00089: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.89.h5\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 113ms/step - loss: 0.6419 - categorical_crossentropy: 0.6405 - accuracy: 0.6595 - precision: 0.5259 - recall: 0.5259 - fmeasure: 0.5259 - val_loss: 0.6272 - val_categorical_crossentropy: 0.6258 - val_accuracy: 0.6739 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 90/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6395 - categorical_crossentropy: 0.6381 - accuracy: 0.6652 - precision: 0.5370 - recall: 0.5370 - fmeasure: 0.5370\n",
      "Epoch 00090: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.90.h5\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6396 - categorical_crossentropy: 0.6382 - accuracy: 0.6659 - precision: 0.5366 - recall: 0.5366 - fmeasure: 0.5366 - val_loss: 0.6534 - val_categorical_crossentropy: 0.6520 - val_accuracy: 0.6413 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 91/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6397 - categorical_crossentropy: 0.6383 - accuracy: 0.6652 - precision: 0.5565 - recall: 0.5565 - fmeasure: 0.5565\n",
      "Epoch 00091: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.91.h5\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6393 - categorical_crossentropy: 0.6379 - accuracy: 0.6681 - precision: 0.5582 - recall: 0.5582 - fmeasure: 0.5582 - val_loss: 0.6287 - val_categorical_crossentropy: 0.6273 - val_accuracy: 0.6522 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 92/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6623 - categorical_crossentropy: 0.6609 - accuracy: 0.6239 - precision: 0.4739 - recall: 0.4739 - fmeasure: 0.4739\n",
      "Epoch 00092: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.92.h5\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 119ms/step - loss: 0.6629 - categorical_crossentropy: 0.6615 - accuracy: 0.6228 - precision: 0.4741 - recall: 0.4741 - fmeasure: 0.4741 - val_loss: 0.6665 - val_categorical_crossentropy: 0.6651 - val_accuracy: 0.5870 - val_precision: 0.5870 - val_recall: 0.5870 - val_fmeasure: 0.5870\n",
      "Epoch 93/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6530 - categorical_crossentropy: 0.6516 - accuracy: 0.6543 - precision: 0.5304 - recall: 0.5304 - fmeasure: 0.5304\n",
      "Epoch 00093: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.93.h5\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 118ms/step - loss: 0.6530 - categorical_crossentropy: 0.6516 - accuracy: 0.6552 - precision: 0.5302 - recall: 0.5302 - fmeasure: 0.5302 - val_loss: 0.6367 - val_categorical_crossentropy: 0.6353 - val_accuracy: 0.6522 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 94/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6407 - categorical_crossentropy: 0.6393 - accuracy: 0.6609 - precision: 0.5565 - recall: 0.5565 - fmeasure: 0.5565\n",
      "Epoch 00094: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.94.h5\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6406 - categorical_crossentropy: 0.6392 - accuracy: 0.6595 - precision: 0.5560 - recall: 0.5560 - fmeasure: 0.5560 - val_loss: 0.6904 - val_categorical_crossentropy: 0.6890 - val_accuracy: 0.5978 - val_precision: 0.5761 - val_recall: 0.5761 - val_fmeasure: 0.5761\n",
      "Epoch 95/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6448 - categorical_crossentropy: 0.6434 - accuracy: 0.6739 - precision: 0.5543 - recall: 0.5543 - fmeasure: 0.5543\n",
      "Epoch 00095: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.95.h5\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 120ms/step - loss: 0.6462 - categorical_crossentropy: 0.6448 - accuracy: 0.6724 - precision: 0.5517 - recall: 0.5517 - fmeasure: 0.5517 - val_loss: 0.6395 - val_categorical_crossentropy: 0.6381 - val_accuracy: 0.6522 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 96/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/116 [============================>.] - ETA: 0s - loss: 0.6455 - categorical_crossentropy: 0.6441 - accuracy: 0.6652 - precision: 0.5348 - recall: 0.5348 - fmeasure: 0.5348- ETA: 6s - loss: 0.6601 - categor\n",
      "Epoch 00096: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.96.h5\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.77174\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 4.164856973147835e-07.\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6445 - categorical_crossentropy: 0.6431 - accuracy: 0.6659 - precision: 0.5366 - recall: 0.5366 - fmeasure: 0.5366 - val_loss: 0.6373 - val_categorical_crossentropy: 0.6359 - val_accuracy: 0.6630 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 97/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6465 - categorical_crossentropy: 0.6451 - accuracy: 0.6630 - precision: 0.5326 - recall: 0.5326 - fmeasure: 0.5326\n",
      "Epoch 00097: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.97.h5\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6452 - categorical_crossentropy: 0.6438 - accuracy: 0.6638 - precision: 0.5345 - recall: 0.5345 - fmeasure: 0.5345 - val_loss: 0.6692 - val_categorical_crossentropy: 0.6678 - val_accuracy: 0.6413 - val_precision: 0.6087 - val_recall: 0.6087 - val_fmeasure: 0.6087\n",
      "Epoch 98/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6505 - categorical_crossentropy: 0.6491 - accuracy: 0.6370 - precision: 0.5283 - recall: 0.5283 - fmeasure: 0.5283\n",
      "Epoch 00098: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.98.h5\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 122ms/step - loss: 0.6513 - categorical_crossentropy: 0.6499 - accuracy: 0.6358 - precision: 0.5259 - recall: 0.5259 - fmeasure: 0.5259 - val_loss: 0.6351 - val_categorical_crossentropy: 0.6337 - val_accuracy: 0.6196 - val_precision: 0.5978 - val_recall: 0.5978 - val_fmeasure: 0.5978\n",
      "Epoch 99/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6499 - categorical_crossentropy: 0.6485 - accuracy: 0.6435 - precision: 0.5239 - recall: 0.5239 - fmeasure: 0.5239\n",
      "Epoch 00099: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.99.h5\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6524 - categorical_crossentropy: 0.6510 - accuracy: 0.6379 - precision: 0.5194 - recall: 0.5194 - fmeasure: 0.5194 - val_loss: 0.6350 - val_categorical_crossentropy: 0.6336 - val_accuracy: 0.6304 - val_precision: 0.6304 - val_recall: 0.6304 - val_fmeasure: 0.6304\n",
      "Epoch 100/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6524 - categorical_crossentropy: 0.6510 - accuracy: 0.6348 - precision: 0.5043 - recall: 0.5043 - fmeasure: 0.5043\n",
      "Epoch 00100: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.100.h5\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 116ms/step - loss: 0.6524 - categorical_crossentropy: 0.6510 - accuracy: 0.6336 - precision: 0.5043 - recall: 0.5043 - fmeasure: 0.5043 - val_loss: 0.6167 - val_categorical_crossentropy: 0.6153 - val_accuracy: 0.6630 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 101/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6448 - categorical_crossentropy: 0.6434 - accuracy: 0.6674 - precision: 0.5196 - recall: 0.5196 - fmeasure: 0.5196\n",
      "Epoch 00101: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.101.h5\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6458 - categorical_crossentropy: 0.6444 - accuracy: 0.6638 - precision: 0.5172 - recall: 0.5172 - fmeasure: 0.5172 - val_loss: 0.6157 - val_categorical_crossentropy: 0.6143 - val_accuracy: 0.6957 - val_precision: 0.6739 - val_recall: 0.6739 - val_fmeasure: 0.6739\n",
      "Epoch 102/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6618 - categorical_crossentropy: 0.6604 - accuracy: 0.6174 - precision: 0.4848 - recall: 0.4848 - fmeasure: 0.4848\n",
      "Epoch 00102: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.102.h5\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6609 - categorical_crossentropy: 0.6595 - accuracy: 0.6164 - precision: 0.4849 - recall: 0.4849 - fmeasure: 0.4849 - val_loss: 0.6503 - val_categorical_crossentropy: 0.6490 - val_accuracy: 0.6196 - val_precision: 0.6087 - val_recall: 0.6087 - val_fmeasure: 0.6087\n",
      "Epoch 103/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6264 - categorical_crossentropy: 0.6250 - accuracy: 0.6783 - precision: 0.5522 - recall: 0.5522 - fmeasure: 0.5522\n",
      "Epoch 00103: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.103.h5\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6268 - categorical_crossentropy: 0.6254 - accuracy: 0.6767 - precision: 0.5517 - recall: 0.5517 - fmeasure: 0.5517 - val_loss: 0.6320 - val_categorical_crossentropy: 0.6306 - val_accuracy: 0.6413 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 104/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6558 - categorical_crossentropy: 0.6544 - accuracy: 0.6174 - precision: 0.5065 - recall: 0.5065 - fmeasure: 0.5065\n",
      "Epoch 00104: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.104.h5\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6575 - categorical_crossentropy: 0.6561 - accuracy: 0.6164 - precision: 0.5043 - recall: 0.5043 - fmeasure: 0.5043 - val_loss: 0.6515 - val_categorical_crossentropy: 0.6501 - val_accuracy: 0.6413 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 105/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6502 - categorical_crossentropy: 0.6488 - accuracy: 0.6435 - precision: 0.5478 - recall: 0.5478 - fmeasure: 0.5478\n",
      "Epoch 00105: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.105.h5\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 120ms/step - loss: 0.6496 - categorical_crossentropy: 0.6482 - accuracy: 0.6466 - precision: 0.5474 - recall: 0.5474 - fmeasure: 0.5474 - val_loss: 0.6334 - val_categorical_crossentropy: 0.6320 - val_accuracy: 0.6413 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 106/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6338 - categorical_crossentropy: 0.6324 - accuracy: 0.6630 - precision: 0.5370 - recall: 0.5370 - fmeasure: 0.5370\n",
      "Epoch 00106: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.106.h5\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6335 - categorical_crossentropy: 0.6321 - accuracy: 0.6659 - precision: 0.5366 - recall: 0.5366 - fmeasure: 0.5366 - val_loss: 0.6701 - val_categorical_crossentropy: 0.6687 - val_accuracy: 0.5652 - val_precision: 0.5543 - val_recall: 0.5543 - val_fmeasure: 0.5543\n",
      "Epoch 107/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6405 - categorical_crossentropy: 0.6391 - accuracy: 0.6587 - precision: 0.5348 - recall: 0.5348 - fmeasure: 0.5348\n",
      "Epoch 00107: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.107.h5\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.77174\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 1.3910622533330754e-07.\n",
      "116/116 [==============================] - 13s 114ms/step - loss: 0.6387 - categorical_crossentropy: 0.6373 - accuracy: 0.6616 - precision: 0.5388 - recall: 0.5388 - fmeasure: 0.5388 - val_loss: 0.6489 - val_categorical_crossentropy: 0.6475 - val_accuracy: 0.6522 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6436 - categorical_crossentropy: 0.6422 - accuracy: 0.6565 - precision: 0.5326 - recall: 0.5326 - fmeasure: 0.5326\n",
      "Epoch 00108: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.108.h5\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 112ms/step - loss: 0.6426 - categorical_crossentropy: 0.6412 - accuracy: 0.6595 - precision: 0.5323 - recall: 0.5323 - fmeasure: 0.5323 - val_loss: 0.6296 - val_categorical_crossentropy: 0.6282 - val_accuracy: 0.6848 - val_precision: 0.6630 - val_recall: 0.6630 - val_fmeasure: 0.6630\n",
      "Epoch 109/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6606 - categorical_crossentropy: 0.6592 - accuracy: 0.6152 - precision: 0.5152 - recall: 0.5152 - fmeasure: 0.5152\n",
      "Epoch 00109: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.109.h5\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 110ms/step - loss: 0.6606 - categorical_crossentropy: 0.6592 - accuracy: 0.6142 - precision: 0.5151 - recall: 0.5151 - fmeasure: 0.5151 - val_loss: 0.6333 - val_categorical_crossentropy: 0.6319 - val_accuracy: 0.6522 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 110/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6463 - categorical_crossentropy: 0.6449 - accuracy: 0.6870 - precision: 0.5326 - recall: 0.5326 - fmeasure: 0.5326\n",
      "Epoch 00110: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.110.h5\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 112ms/step - loss: 0.6474 - categorical_crossentropy: 0.6460 - accuracy: 0.6875 - precision: 0.5323 - recall: 0.5323 - fmeasure: 0.5323 - val_loss: 0.6590 - val_categorical_crossentropy: 0.6576 - val_accuracy: 0.6413 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 111/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6568 - categorical_crossentropy: 0.6554 - accuracy: 0.6065 - precision: 0.4935 - recall: 0.4935 - fmeasure: 0.4935\n",
      "Epoch 00111: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.111.h5\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 111ms/step - loss: 0.6568 - categorical_crossentropy: 0.6554 - accuracy: 0.6056 - precision: 0.4935 - recall: 0.4935 - fmeasure: 0.4935 - val_loss: 0.6413 - val_categorical_crossentropy: 0.6399 - val_accuracy: 0.6522 - val_precision: 0.5978 - val_recall: 0.5978 - val_fmeasure: 0.5978\n",
      "Epoch 112/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6402 - categorical_crossentropy: 0.6388 - accuracy: 0.6696 - precision: 0.5304 - recall: 0.5304 - fmeasure: 0.5304\n",
      "Epoch 00112: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.112.h5\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6410 - categorical_crossentropy: 0.6397 - accuracy: 0.6681 - precision: 0.5280 - recall: 0.5280 - fmeasure: 0.5280 - val_loss: 0.6458 - val_categorical_crossentropy: 0.6444 - val_accuracy: 0.6739 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 113/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6385 - categorical_crossentropy: 0.6371 - accuracy: 0.6391 - precision: 0.5174 - recall: 0.5174 - fmeasure: 0.5174\n",
      "Epoch 00113: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.113.h5\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6387 - categorical_crossentropy: 0.6373 - accuracy: 0.6401 - precision: 0.5172 - recall: 0.5172 - fmeasure: 0.5172 - val_loss: 0.6432 - val_categorical_crossentropy: 0.6418 - val_accuracy: 0.6413 - val_precision: 0.5978 - val_recall: 0.5978 - val_fmeasure: 0.5978\n",
      "Epoch 114/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6397 - categorical_crossentropy: 0.6383 - accuracy: 0.6630 - precision: 0.5304 - recall: 0.5304 - fmeasure: 0.5304- ETA: 6s - loss: 0.6193 - cat\n",
      "Epoch 00114: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.114.h5\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6399 - categorical_crossentropy: 0.6385 - accuracy: 0.6638 - precision: 0.5302 - recall: 0.5302 - fmeasure: 0.5302 - val_loss: 0.6510 - val_categorical_crossentropy: 0.6496 - val_accuracy: 0.6413 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 115/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6441 - categorical_crossentropy: 0.6427 - accuracy: 0.6543 - precision: 0.5370 - recall: 0.5370 - fmeasure: 0.5370\n",
      "Epoch 00115: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.115.h5\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 118ms/step - loss: 0.6427 - categorical_crossentropy: 0.6413 - accuracy: 0.6573 - precision: 0.5388 - recall: 0.5388 - fmeasure: 0.5388 - val_loss: 0.6775 - val_categorical_crossentropy: 0.6761 - val_accuracy: 0.5870 - val_precision: 0.5761 - val_recall: 0.5761 - val_fmeasure: 0.5761\n",
      "Epoch 116/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6487 - categorical_crossentropy: 0.6473 - accuracy: 0.6326 - precision: 0.5087 - recall: 0.5087 - fmeasure: 0.5087\n",
      "Epoch 00116: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.116.h5\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 119ms/step - loss: 0.6479 - categorical_crossentropy: 0.6465 - accuracy: 0.6358 - precision: 0.5108 - recall: 0.5108 - fmeasure: 0.5108 - val_loss: 0.6414 - val_categorical_crossentropy: 0.6400 - val_accuracy: 0.6739 - val_precision: 0.6304 - val_recall: 0.6304 - val_fmeasure: 0.6304\n",
      "Epoch 117/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6469 - categorical_crossentropy: 0.6455 - accuracy: 0.6630 - precision: 0.5478 - recall: 0.5478 - fmeasure: 0.5478\n",
      "Epoch 00117: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.117.h5\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 119ms/step - loss: 0.6473 - categorical_crossentropy: 0.6459 - accuracy: 0.6616 - precision: 0.5453 - recall: 0.5453 - fmeasure: 0.5453 - val_loss: 0.6265 - val_categorical_crossentropy: 0.6251 - val_accuracy: 0.6739 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 118/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6561 - categorical_crossentropy: 0.6547 - accuracy: 0.6283 - precision: 0.4848 - recall: 0.4848 - fmeasure: 0.4848\n",
      "Epoch 00118: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.118.h5\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.77174\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 4.6461477438697334e-08.\n",
      "116/116 [==============================] - 14s 121ms/step - loss: 0.6564 - categorical_crossentropy: 0.6550 - accuracy: 0.6272 - precision: 0.4849 - recall: 0.4849 - fmeasure: 0.4849 - val_loss: 0.6105 - val_categorical_crossentropy: 0.6091 - val_accuracy: 0.6848 - val_precision: 0.6739 - val_recall: 0.6739 - val_fmeasure: 0.6739\n",
      "Epoch 119/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6557 - categorical_crossentropy: 0.6543 - accuracy: 0.6304 - precision: 0.5152 - recall: 0.5152 - fmeasure: 0.5152\n",
      "Epoch 00119: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.119.h5\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 113ms/step - loss: 0.6562 - categorical_crossentropy: 0.6548 - accuracy: 0.6272 - precision: 0.5129 - recall: 0.5129 - fmeasure: 0.5129 - val_loss: 0.5768 - val_categorical_crossentropy: 0.5754 - val_accuracy: 0.7609 - val_precision: 0.7609 - val_recall: 0.7609 - val_fmeasure: 0.7609\n",
      "Epoch 120/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/116 [============================>.] - ETA: 0s - loss: 0.6444 - categorical_crossentropy: 0.6430 - accuracy: 0.6543 - precision: 0.5413 - recall: 0.5413 - fmeasure: 0.5413\n",
      "Epoch 00120: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.120.h5\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 114ms/step - loss: 0.6452 - categorical_crossentropy: 0.6438 - accuracy: 0.6552 - precision: 0.5431 - recall: 0.5431 - fmeasure: 0.5431 - val_loss: 0.6278 - val_categorical_crossentropy: 0.6264 - val_accuracy: 0.6630 - val_precision: 0.6630 - val_recall: 0.6630 - val_fmeasure: 0.6630\n",
      "Epoch 121/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6636 - categorical_crossentropy: 0.6622 - accuracy: 0.6478 - precision: 0.5130 - recall: 0.5130 - fmeasure: 0.5130\n",
      "Epoch 00121: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.121.h5\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6622 - categorical_crossentropy: 0.6608 - accuracy: 0.6509 - precision: 0.5151 - recall: 0.5151 - fmeasure: 0.5151 - val_loss: 0.6321 - val_categorical_crossentropy: 0.6307 - val_accuracy: 0.6848 - val_precision: 0.6630 - val_recall: 0.6630 - val_fmeasure: 0.6630\n",
      "Epoch 122/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6602 - categorical_crossentropy: 0.6588 - accuracy: 0.6391 - precision: 0.5261 - recall: 0.5261 - fmeasure: 0.5261\n",
      "Epoch 00122: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.122.h5\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 114ms/step - loss: 0.6617 - categorical_crossentropy: 0.6603 - accuracy: 0.6379 - precision: 0.5259 - recall: 0.5259 - fmeasure: 0.5259 - val_loss: 0.6378 - val_categorical_crossentropy: 0.6364 - val_accuracy: 0.6522 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 123/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6529 - categorical_crossentropy: 0.6515 - accuracy: 0.6413 - precision: 0.5196 - recall: 0.5196 - fmeasure: 0.5196\n",
      "Epoch 00123: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.123.h5\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 113ms/step - loss: 0.6528 - categorical_crossentropy: 0.6514 - accuracy: 0.6422 - precision: 0.5194 - recall: 0.5194 - fmeasure: 0.5194 - val_loss: 0.6352 - val_categorical_crossentropy: 0.6338 - val_accuracy: 0.6630 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 124/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6653 - categorical_crossentropy: 0.6640 - accuracy: 0.6304 - precision: 0.5087 - recall: 0.5087 - fmeasure: 0.5087\n",
      "Epoch 00124: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.124.h5\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 114ms/step - loss: 0.6639 - categorical_crossentropy: 0.6625 - accuracy: 0.6336 - precision: 0.5129 - recall: 0.5129 - fmeasure: 0.5129 - val_loss: 0.6628 - val_categorical_crossentropy: 0.6614 - val_accuracy: 0.6087 - val_precision: 0.5870 - val_recall: 0.5870 - val_fmeasure: 0.5870\n",
      "Epoch 125/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6575 - categorical_crossentropy: 0.6561 - accuracy: 0.6391 - precision: 0.4913 - recall: 0.4913 - fmeasure: 0.4913\n",
      "Epoch 00125: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.125.h5\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6575 - categorical_crossentropy: 0.6561 - accuracy: 0.6379 - precision: 0.4914 - recall: 0.4914 - fmeasure: 0.4914 - val_loss: 0.6311 - val_categorical_crossentropy: 0.6297 - val_accuracy: 0.6413 - val_precision: 0.6304 - val_recall: 0.6304 - val_fmeasure: 0.6304\n",
      "Epoch 126/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6608 - categorical_crossentropy: 0.6594 - accuracy: 0.6261 - precision: 0.5022 - recall: 0.5022 - fmeasure: 0.5022\n",
      "Epoch 00126: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.126.h5\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 121ms/step - loss: 0.6609 - categorical_crossentropy: 0.6595 - accuracy: 0.6272 - precision: 0.5022 - recall: 0.5022 - fmeasure: 0.5022 - val_loss: 0.6300 - val_categorical_crossentropy: 0.6286 - val_accuracy: 0.6739 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 127/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6597 - categorical_crossentropy: 0.6583 - accuracy: 0.6304 - precision: 0.4978 - recall: 0.4978 - fmeasure: 0.4978\n",
      "Epoch 00127: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.127.h5\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 120ms/step - loss: 0.6592 - categorical_crossentropy: 0.6578 - accuracy: 0.6315 - precision: 0.4978 - recall: 0.4978 - fmeasure: 0.4978 - val_loss: 0.6122 - val_categorical_crossentropy: 0.6108 - val_accuracy: 0.6957 - val_precision: 0.6739 - val_recall: 0.6739 - val_fmeasure: 0.6739\n",
      "Epoch 128/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6586 - categorical_crossentropy: 0.6572 - accuracy: 0.6152 - precision: 0.5239 - recall: 0.5239 - fmeasure: 0.5239\n",
      "Epoch 00128: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.128.h5\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 120ms/step - loss: 0.6583 - categorical_crossentropy: 0.6569 - accuracy: 0.6185 - precision: 0.5237 - recall: 0.5237 - fmeasure: 0.5237 - val_loss: 0.6316 - val_categorical_crossentropy: 0.6302 - val_accuracy: 0.6630 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 129/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6439 - categorical_crossentropy: 0.6425 - accuracy: 0.6696 - precision: 0.5522 - recall: 0.5522 - fmeasure: 0.5522\n",
      "Epoch 00129: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.129.h5\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.77174\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 1.5518133132275127e-08.\n",
      "116/116 [==============================] - 14s 118ms/step - loss: 0.6433 - categorical_crossentropy: 0.6419 - accuracy: 0.6681 - precision: 0.5517 - recall: 0.5517 - fmeasure: 0.5517 - val_loss: 0.6810 - val_categorical_crossentropy: 0.6796 - val_accuracy: 0.5978 - val_precision: 0.5870 - val_recall: 0.5870 - val_fmeasure: 0.5870\n",
      "Epoch 130/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6395 - categorical_crossentropy: 0.6381 - accuracy: 0.6587 - precision: 0.5478 - recall: 0.5478 - fmeasure: 0.5478\n",
      "Epoch 00130: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.130.h5\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6404 - categorical_crossentropy: 0.6390 - accuracy: 0.6573 - precision: 0.5453 - recall: 0.5453 - fmeasure: 0.5453 - val_loss: 0.6614 - val_categorical_crossentropy: 0.6600 - val_accuracy: 0.6413 - val_precision: 0.6304 - val_recall: 0.6304 - val_fmeasure: 0.6304\n",
      "Epoch 131/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6635 - categorical_crossentropy: 0.6621 - accuracy: 0.6261 - precision: 0.5043 - recall: 0.5043 - fmeasure: 0.5043\n",
      "Epoch 00131: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.131.h5\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 122ms/step - loss: 0.6644 - categorical_crossentropy: 0.6630 - accuracy: 0.6250 - precision: 0.5043 - recall: 0.5043 - fmeasure: 0.5043 - val_loss: 0.6347 - val_categorical_crossentropy: 0.6333 - val_accuracy: 0.6413 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 132/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/116 [============================>.] - ETA: 0s - loss: 0.6427 - categorical_crossentropy: 0.6413 - accuracy: 0.6717 - precision: 0.5587 - recall: 0.5587 - fmeasure: 0.5587\n",
      "Epoch 00132: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.132.h5\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6418 - categorical_crossentropy: 0.6404 - accuracy: 0.6724 - precision: 0.5582 - recall: 0.5582 - fmeasure: 0.5582 - val_loss: 0.6435 - val_categorical_crossentropy: 0.6421 - val_accuracy: 0.6413 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 133/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6300 - categorical_crossentropy: 0.6287 - accuracy: 0.6978 - precision: 0.5652 - recall: 0.5652 - fmeasure: 0.5652\n",
      "Epoch 00133: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.133.h5\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 113ms/step - loss: 0.6292 - categorical_crossentropy: 0.6278 - accuracy: 0.7004 - precision: 0.5690 - recall: 0.5690 - fmeasure: 0.5690 - val_loss: 0.6354 - val_categorical_crossentropy: 0.6340 - val_accuracy: 0.6848 - val_precision: 0.6087 - val_recall: 0.6087 - val_fmeasure: 0.6087\n",
      "Epoch 134/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6413 - categorical_crossentropy: 0.6399 - accuracy: 0.6587 - precision: 0.5283 - recall: 0.5283 - fmeasure: 0.5283- ETA: 5s - loss: 0.6151 - categorical_cr\n",
      "Epoch 00134: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.134.h5\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 113ms/step - loss: 0.6454 - categorical_crossentropy: 0.6440 - accuracy: 0.6552 - precision: 0.5259 - recall: 0.5259 - fmeasure: 0.5259 - val_loss: 0.6237 - val_categorical_crossentropy: 0.6223 - val_accuracy: 0.6630 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 135/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6504 - categorical_crossentropy: 0.6490 - accuracy: 0.6543 - precision: 0.5391 - recall: 0.5391 - fmeasure: 0.5391\n",
      "Epoch 00135: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.135.h5\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 111ms/step - loss: 0.6510 - categorical_crossentropy: 0.6496 - accuracy: 0.6509 - precision: 0.5366 - recall: 0.5366 - fmeasure: 0.5366 - val_loss: 0.6064 - val_categorical_crossentropy: 0.6050 - val_accuracy: 0.7065 - val_precision: 0.7065 - val_recall: 0.7065 - val_fmeasure: 0.7065\n",
      "Epoch 136/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6415 - categorical_crossentropy: 0.6401 - accuracy: 0.6391 - precision: 0.5435 - recall: 0.5435 - fmeasure: 0.5435\n",
      "Epoch 00136: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.136.h5\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6408 - categorical_crossentropy: 0.6394 - accuracy: 0.6401 - precision: 0.5431 - recall: 0.5431 - fmeasure: 0.5431 - val_loss: 0.6389 - val_categorical_crossentropy: 0.6375 - val_accuracy: 0.6413 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 137/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6555 - categorical_crossentropy: 0.6541 - accuracy: 0.6109 - precision: 0.5152 - recall: 0.5152 - fmeasure: 0.5152\n",
      "Epoch 00137: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.137.h5\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 119ms/step - loss: 0.6544 - categorical_crossentropy: 0.6530 - accuracy: 0.6121 - precision: 0.5172 - recall: 0.5172 - fmeasure: 0.5172 - val_loss: 0.6282 - val_categorical_crossentropy: 0.6268 - val_accuracy: 0.6848 - val_precision: 0.6630 - val_recall: 0.6630 - val_fmeasure: 0.6630\n",
      "Epoch 138/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6758 - categorical_crossentropy: 0.6744 - accuracy: 0.6261 - precision: 0.5109 - recall: 0.5109 - fmeasure: 0.5109\n",
      "Epoch 00138: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.138.h5\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6749 - categorical_crossentropy: 0.6735 - accuracy: 0.6293 - precision: 0.5108 - recall: 0.5108 - fmeasure: 0.5108 - val_loss: 0.6074 - val_categorical_crossentropy: 0.6060 - val_accuracy: 0.6848 - val_precision: 0.6630 - val_recall: 0.6630 - val_fmeasure: 0.6630\n",
      "Epoch 139/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6471 - categorical_crossentropy: 0.6457 - accuracy: 0.6457 - precision: 0.5239 - recall: 0.5239 - fmeasure: 0.5239\n",
      "Epoch 00139: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.139.h5\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6455 - categorical_crossentropy: 0.6441 - accuracy: 0.6487 - precision: 0.5280 - recall: 0.5280 - fmeasure: 0.5280 - val_loss: 0.6399 - val_categorical_crossentropy: 0.6385 - val_accuracy: 0.6522 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 140/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6488 - categorical_crossentropy: 0.6474 - accuracy: 0.6609 - precision: 0.5261 - recall: 0.5261 - fmeasure: 0.5261\n",
      "Epoch 00140: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.140.h5\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.77174\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 5.18305627394966e-09.\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6480 - categorical_crossentropy: 0.6466 - accuracy: 0.6616 - precision: 0.5280 - recall: 0.5280 - fmeasure: 0.5280 - val_loss: 0.5897 - val_categorical_crossentropy: 0.5883 - val_accuracy: 0.7065 - val_precision: 0.6848 - val_recall: 0.6848 - val_fmeasure: 0.6848\n",
      "Epoch 141/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6597 - categorical_crossentropy: 0.6583 - accuracy: 0.6261 - precision: 0.5109 - recall: 0.5109 - fmeasure: 0.5109\n",
      "Epoch 00141: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.141.h5\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 112ms/step - loss: 0.6593 - categorical_crossentropy: 0.6579 - accuracy: 0.6250 - precision: 0.5108 - recall: 0.5108 - fmeasure: 0.5108 - val_loss: 0.6470 - val_categorical_crossentropy: 0.6456 - val_accuracy: 0.6848 - val_precision: 0.6087 - val_recall: 0.6087 - val_fmeasure: 0.6087\n",
      "Epoch 142/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6443 - categorical_crossentropy: 0.6429 - accuracy: 0.6457 - precision: 0.5196 - recall: 0.5196 - fmeasure: 0.5196\n",
      "Epoch 00142: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.142.h5\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 112ms/step - loss: 0.6435 - categorical_crossentropy: 0.6421 - accuracy: 0.6466 - precision: 0.5216 - recall: 0.5216 - fmeasure: 0.5216 - val_loss: 0.6499 - val_categorical_crossentropy: 0.6485 - val_accuracy: 0.6413 - val_precision: 0.6087 - val_recall: 0.6087 - val_fmeasure: 0.6087\n",
      "Epoch 143/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6346 - categorical_crossentropy: 0.6332 - accuracy: 0.6739 - precision: 0.5370 - recall: 0.5370 - fmeasure: 0.5370\n",
      "Epoch 00143: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.143.h5\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6340 - categorical_crossentropy: 0.6326 - accuracy: 0.6746 - precision: 0.5388 - recall: 0.5388 - fmeasure: 0.5388 - val_loss: 0.6517 - val_categorical_crossentropy: 0.6503 - val_accuracy: 0.6304 - val_precision: 0.6087 - val_recall: 0.6087 - val_fmeasure: 0.6087\n",
      "Epoch 144/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/116 [============================>.] - ETA: 0s - loss: 0.6587 - categorical_crossentropy: 0.6573 - accuracy: 0.6217 - precision: 0.5087 - recall: 0.5087 - fmeasure: 0.5087\n",
      "Epoch 00144: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.144.h5\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 114ms/step - loss: 0.6579 - categorical_crossentropy: 0.6565 - accuracy: 0.6228 - precision: 0.5086 - recall: 0.5086 - fmeasure: 0.5086 - val_loss: 0.6451 - val_categorical_crossentropy: 0.6437 - val_accuracy: 0.6413 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 145/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6409 - categorical_crossentropy: 0.6395 - accuracy: 0.6826 - precision: 0.5522 - recall: 0.5522 - fmeasure: 0.5522\n",
      "Epoch 00145: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.145.h5\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6404 - categorical_crossentropy: 0.6390 - accuracy: 0.6832 - precision: 0.5539 - recall: 0.5539 - fmeasure: 0.5539 - val_loss: 0.6220 - val_categorical_crossentropy: 0.6206 - val_accuracy: 0.6957 - val_precision: 0.6957 - val_recall: 0.6957 - val_fmeasure: 0.6957\n",
      "Epoch 146/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6607 - categorical_crossentropy: 0.6593 - accuracy: 0.6239 - precision: 0.5043 - recall: 0.5043 - fmeasure: 0.5043\n",
      "Epoch 00146: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.146.h5\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 113ms/step - loss: 0.6594 - categorical_crossentropy: 0.6580 - accuracy: 0.6272 - precision: 0.5065 - recall: 0.5065 - fmeasure: 0.5065 - val_loss: 0.6432 - val_categorical_crossentropy: 0.6418 - val_accuracy: 0.6522 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 147/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6557 - categorical_crossentropy: 0.6543 - accuracy: 0.6283 - precision: 0.4957 - recall: 0.4957 - fmeasure: 0.4957\n",
      "Epoch 00147: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.147.h5\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 112ms/step - loss: 0.6552 - categorical_crossentropy: 0.6538 - accuracy: 0.6293 - precision: 0.4978 - recall: 0.4978 - fmeasure: 0.4978 - val_loss: 0.6254 - val_categorical_crossentropy: 0.6240 - val_accuracy: 0.6739 - val_precision: 0.6739 - val_recall: 0.6739 - val_fmeasure: 0.6739\n",
      "Epoch 148/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6540 - categorical_crossentropy: 0.6526 - accuracy: 0.6326 - precision: 0.4891 - recall: 0.4891 - fmeasure: 0.4891\n",
      "Epoch 00148: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.148.h5\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 114ms/step - loss: 0.6530 - categorical_crossentropy: 0.6516 - accuracy: 0.6358 - precision: 0.4914 - recall: 0.4914 - fmeasure: 0.4914 - val_loss: 0.6327 - val_categorical_crossentropy: 0.6313 - val_accuracy: 0.6630 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 149/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6458 - categorical_crossentropy: 0.6444 - accuracy: 0.6609 - precision: 0.5326 - recall: 0.5326 - fmeasure: 0.5326\n",
      "Epoch 00149: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.149.h5\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 118ms/step - loss: 0.6454 - categorical_crossentropy: 0.6440 - accuracy: 0.6616 - precision: 0.5323 - recall: 0.5323 - fmeasure: 0.5323 - val_loss: 0.6511 - val_categorical_crossentropy: 0.6497 - val_accuracy: 0.6522 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 150/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6589 - categorical_crossentropy: 0.6575 - accuracy: 0.6304 - precision: 0.4891 - recall: 0.4891 - fmeasure: 0.4891\n",
      "Epoch 00150: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.150.h5\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6600 - categorical_crossentropy: 0.6586 - accuracy: 0.6293 - precision: 0.4871 - recall: 0.4871 - fmeasure: 0.4871 - val_loss: 0.6549 - val_categorical_crossentropy: 0.6535 - val_accuracy: 0.6304 - val_precision: 0.6087 - val_recall: 0.6087 - val_fmeasure: 0.6087\n",
      "Epoch 151/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6436 - categorical_crossentropy: 0.6422 - accuracy: 0.6348 - precision: 0.5304 - recall: 0.5304 - fmeasure: 0.5304\n",
      "Epoch 00151: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.151.h5\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.77174\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 1.7311407729536655e-09.\n",
      "116/116 [==============================] - 13s 116ms/step - loss: 0.6435 - categorical_crossentropy: 0.6421 - accuracy: 0.6358 - precision: 0.5280 - recall: 0.5280 - fmeasure: 0.5280 - val_loss: 0.6469 - val_categorical_crossentropy: 0.6455 - val_accuracy: 0.6522 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 152/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6516 - categorical_crossentropy: 0.6502 - accuracy: 0.6283 - precision: 0.4978 - recall: 0.4978 - fmeasure: 0.4978\n",
      "Epoch 00152: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.152.h5\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6503 - categorical_crossentropy: 0.6489 - accuracy: 0.6315 - precision: 0.4978 - recall: 0.4978 - fmeasure: 0.4978 - val_loss: 0.6336 - val_categorical_crossentropy: 0.6322 - val_accuracy: 0.6522 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 153/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6396 - categorical_crossentropy: 0.6382 - accuracy: 0.6478 - precision: 0.5565 - recall: 0.5565 - fmeasure: 0.5565\n",
      "Epoch 00153: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.153.h5\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 119ms/step - loss: 0.6396 - categorical_crossentropy: 0.6382 - accuracy: 0.6487 - precision: 0.5539 - recall: 0.5539 - fmeasure: 0.5539 - val_loss: 0.6257 - val_categorical_crossentropy: 0.6243 - val_accuracy: 0.6957 - val_precision: 0.6413 - val_recall: 0.6413 - val_fmeasure: 0.6413\n",
      "Epoch 154/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6415 - categorical_crossentropy: 0.6401 - accuracy: 0.6587 - precision: 0.5565 - recall: 0.5565 - fmeasure: 0.5565\n",
      "Epoch 00154: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.154.h5\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 119ms/step - loss: 0.6406 - categorical_crossentropy: 0.6392 - accuracy: 0.6595 - precision: 0.5582 - recall: 0.5582 - fmeasure: 0.5582 - val_loss: 0.6244 - val_categorical_crossentropy: 0.6230 - val_accuracy: 0.6304 - val_precision: 0.6087 - val_recall: 0.6087 - val_fmeasure: 0.6087\n",
      "Epoch 155/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6494 - categorical_crossentropy: 0.6480 - accuracy: 0.6587 - precision: 0.5370 - recall: 0.5370 - fmeasure: 0.5370\n",
      "Epoch 00155: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.155.h5\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 13s 115ms/step - loss: 0.6493 - categorical_crossentropy: 0.6479 - accuracy: 0.6573 - precision: 0.5345 - recall: 0.5345 - fmeasure: 0.5345 - val_loss: 0.6487 - val_categorical_crossentropy: 0.6473 - val_accuracy: 0.6196 - val_precision: 0.5978 - val_recall: 0.5978 - val_fmeasure: 0.5978\n",
      "Epoch 156/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/116 [============================>.] - ETA: 0s - loss: 0.6397 - categorical_crossentropy: 0.6383 - accuracy: 0.6739 - precision: 0.5565 - recall: 0.5565 - fmeasure: 0.5565\n",
      "Epoch 00156: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.156.h5\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6399 - categorical_crossentropy: 0.6385 - accuracy: 0.6746 - precision: 0.5560 - recall: 0.5560 - fmeasure: 0.5560 - val_loss: 0.6680 - val_categorical_crossentropy: 0.6666 - val_accuracy: 0.6304 - val_precision: 0.6196 - val_recall: 0.6196 - val_fmeasure: 0.6196\n",
      "Epoch 157/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6517 - categorical_crossentropy: 0.6503 - accuracy: 0.6478 - precision: 0.5565 - recall: 0.5565 - fmeasure: 0.5565\n",
      "Epoch 00157: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.157.h5\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6504 - categorical_crossentropy: 0.6490 - accuracy: 0.6509 - precision: 0.5603 - recall: 0.5603 - fmeasure: 0.5603 - val_loss: 0.6444 - val_categorical_crossentropy: 0.6430 - val_accuracy: 0.6522 - val_precision: 0.6522 - val_recall: 0.6522 - val_fmeasure: 0.6522\n",
      "Epoch 158/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6595 - categorical_crossentropy: 0.6581 - accuracy: 0.6217 - precision: 0.5065 - recall: 0.5065 - fmeasure: 0.5065\n",
      "Epoch 00158: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.158.h5\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 119ms/step - loss: 0.6592 - categorical_crossentropy: 0.6578 - accuracy: 0.6228 - precision: 0.5086 - recall: 0.5086 - fmeasure: 0.5086 - val_loss: 0.6905 - val_categorical_crossentropy: 0.6891 - val_accuracy: 0.5870 - val_precision: 0.5652 - val_recall: 0.5652 - val_fmeasure: 0.5652\n",
      "Epoch 159/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6513 - categorical_crossentropy: 0.6499 - accuracy: 0.6348 - precision: 0.5022 - recall: 0.5022 - fmeasure: 0.5022\n",
      "Epoch 00159: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.159.h5\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 117ms/step - loss: 0.6518 - categorical_crossentropy: 0.6504 - accuracy: 0.6358 - precision: 0.5022 - recall: 0.5022 - fmeasure: 0.5022 - val_loss: 0.6743 - val_categorical_crossentropy: 0.6729 - val_accuracy: 0.5978 - val_precision: 0.5761 - val_recall: 0.5761 - val_fmeasure: 0.5761\n",
      "Epoch 160/160\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.6497 - categorical_crossentropy: 0.6483 - accuracy: 0.6587 - precision: 0.5391 - recall: 0.5391 - fmeasure: 0.5391\n",
      "Epoch 00160: saving model to tmp/224avrpoolingattentionfGlobalavrk=18dropout/weights.160.h5\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.77174\n",
      "116/116 [==============================] - 14s 120ms/step - loss: 0.6504 - categorical_crossentropy: 0.6490 - accuracy: 0.6595 - precision: 0.5366 - recall: 0.5366 - fmeasure: 0.5366 - val_loss: 0.6352 - val_categorical_crossentropy: 0.6338 - val_accuracy: 0.6522 - val_precision: 0.6304 - val_recall: 0.6304 - val_fmeasure: 0.6304\n"
     ]
    }
   ],
   "source": [
    "main(batch_sizes=[2, 2],\n",
    "          crop_size=[32, 32, 32],\n",
    "          train_subset = list(range(9)),\n",
    "          val_subset = [1],\n",
    "          model_path = None,\n",
    "          random_move=4,\n",
    "          learning_rate=3e-4,\n",
    "          segmentation_task_ratio=0.2,\n",
    "          weight_decay=1e-6,\n",
    "          save_folder='224avrpoolingattentionfGlobalavrk=18dropout',\n",
    "          epochs=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
